{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry2HcqIGd_Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib. pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, MaxPooling2D, Convolution2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufgCwvLlSmeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0bef148-9baa-47e5-c50b-d2b7877d2aab"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdHwmgwOpEfx",
        "colab_type": "text"
      },
      "source": [
        "#Classification with DNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itLZvsRb0OMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAfosLKHYv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = train_x.reshape(60000,28,28,1)\n",
        "test_x = test_x.reshape(10000,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGRlT3T5dppT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y= to_categorical(train_y)\n",
        "test_y= to_categorical(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mOenQzX5ysX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x =tf.image.convert_image_dtype(train_x, tf.float32)\n",
        "train_x=train_x/255\n",
        "test_x =tf.image.convert_image_dtype(test_x, tf.float32)\n",
        "test_x = test_x/255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtornrlphDWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=10000).batch(batch_size=128).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OAXcyVBmFma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=10000).batch(batch_size=128).repeat()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwU7v_I5mVaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.01),loss='categorical_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESR1-OSsmcdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c608629-cfbd-4f1e-852a-45679fcd4cc2"
      },
      "source": [
        "batch_size=128\n",
        "Epochs=250\n",
        "STEPS_PER_EPOCH=100\n",
        "\n",
        "history=model.fit(train_dataset,epochs=Epochs,validation_data=test_dataset,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 steps, validate on 50 steps\n",
            "Epoch 1/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.4141 - accuracy: 0.5197 - val_loss: 0.8866 - val_accuracy: 0.6780\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7650 - accuracy: 0.7226 - val_loss: 0.6890 - val_accuracy: 0.7534\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6243 - accuracy: 0.7749 - val_loss: 0.6318 - val_accuracy: 0.7680\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5822 - accuracy: 0.7903 - val_loss: 0.5575 - val_accuracy: 0.7994\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5442 - accuracy: 0.7997 - val_loss: 0.5498 - val_accuracy: 0.8008\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5267 - accuracy: 0.8089 - val_loss: 0.5372 - val_accuracy: 0.8019\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4927 - accuracy: 0.8229 - val_loss: 0.5048 - val_accuracy: 0.8164\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.8304 - val_loss: 0.4919 - val_accuracy: 0.8225\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8281 - val_loss: 0.5032 - val_accuracy: 0.8175\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.8341 - val_loss: 0.4848 - val_accuracy: 0.8203\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4491 - accuracy: 0.8401 - val_loss: 0.4710 - val_accuracy: 0.8266\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4341 - accuracy: 0.8471 - val_loss: 0.4625 - val_accuracy: 0.8358\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4431 - accuracy: 0.8424 - val_loss: 0.4797 - val_accuracy: 0.8217\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8464 - val_loss: 0.4522 - val_accuracy: 0.8345\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8463 - val_loss: 0.4499 - val_accuracy: 0.8402\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8505 - val_loss: 0.4559 - val_accuracy: 0.8356\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8487 - val_loss: 0.4536 - val_accuracy: 0.8334\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8543 - val_loss: 0.4523 - val_accuracy: 0.8367\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8557 - val_loss: 0.4282 - val_accuracy: 0.8431\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8533 - val_loss: 0.4328 - val_accuracy: 0.8444\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3898 - accuracy: 0.8613 - val_loss: 0.4246 - val_accuracy: 0.8517\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3834 - accuracy: 0.8655 - val_loss: 0.4348 - val_accuracy: 0.8466\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8573 - val_loss: 0.4130 - val_accuracy: 0.8498\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3929 - accuracy: 0.8586 - val_loss: 0.4213 - val_accuracy: 0.8527\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.8584 - val_loss: 0.4294 - val_accuracy: 0.8456\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3767 - accuracy: 0.8658 - val_loss: 0.4339 - val_accuracy: 0.8502\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8640 - val_loss: 0.4311 - val_accuracy: 0.8467\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8652 - val_loss: 0.4177 - val_accuracy: 0.8489\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3715 - accuracy: 0.8655 - val_loss: 0.4341 - val_accuracy: 0.8444\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8658 - val_loss: 0.3938 - val_accuracy: 0.8606\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3837 - accuracy: 0.8629 - val_loss: 0.4151 - val_accuracy: 0.8541\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8731 - val_loss: 0.4028 - val_accuracy: 0.8530\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3656 - accuracy: 0.8676 - val_loss: 0.4218 - val_accuracy: 0.8478\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3529 - accuracy: 0.8704 - val_loss: 0.3880 - val_accuracy: 0.8652\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3529 - accuracy: 0.8715 - val_loss: 0.3856 - val_accuracy: 0.8644\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8719 - val_loss: 0.4007 - val_accuracy: 0.8566\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8777 - val_loss: 0.4012 - val_accuracy: 0.8550\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.8705 - val_loss: 0.4036 - val_accuracy: 0.8578\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3489 - accuracy: 0.8730 - val_loss: 0.3940 - val_accuracy: 0.8606\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3527 - accuracy: 0.8744 - val_loss: 0.3867 - val_accuracy: 0.8634\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3432 - accuracy: 0.8759 - val_loss: 0.4053 - val_accuracy: 0.8606\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3536 - accuracy: 0.8705 - val_loss: 0.3807 - val_accuracy: 0.8645\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3465 - accuracy: 0.8719 - val_loss: 0.3895 - val_accuracy: 0.8591\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3363 - accuracy: 0.8791 - val_loss: 0.3921 - val_accuracy: 0.8603\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8816 - val_loss: 0.3920 - val_accuracy: 0.8583\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8779 - val_loss: 0.3999 - val_accuracy: 0.8553\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8787 - val_loss: 0.3780 - val_accuracy: 0.8703\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8752 - val_loss: 0.3784 - val_accuracy: 0.8633\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3267 - accuracy: 0.8823 - val_loss: 0.3749 - val_accuracy: 0.8673\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8820 - val_loss: 0.3849 - val_accuracy: 0.8683\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3463 - accuracy: 0.8773 - val_loss: 0.3744 - val_accuracy: 0.8622\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8805 - val_loss: 0.3810 - val_accuracy: 0.8683\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3273 - accuracy: 0.8788 - val_loss: 0.3767 - val_accuracy: 0.8631\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3256 - accuracy: 0.8811 - val_loss: 0.3722 - val_accuracy: 0.8717\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3137 - accuracy: 0.8877 - val_loss: 0.3806 - val_accuracy: 0.8647\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8780 - val_loss: 0.3794 - val_accuracy: 0.8656\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.8820 - val_loss: 0.3691 - val_accuracy: 0.8667\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8824 - val_loss: 0.3855 - val_accuracy: 0.8650\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8866 - val_loss: 0.3700 - val_accuracy: 0.8684\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3181 - accuracy: 0.8845 - val_loss: 0.3641 - val_accuracy: 0.8712\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.8846 - val_loss: 0.3865 - val_accuracy: 0.8612\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3147 - accuracy: 0.8794 - val_loss: 0.3653 - val_accuracy: 0.8697\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8859 - val_loss: 0.3710 - val_accuracy: 0.8698\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.8920 - val_loss: 0.3558 - val_accuracy: 0.8747\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8831 - val_loss: 0.3830 - val_accuracy: 0.8656\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.8893 - val_loss: 0.3734 - val_accuracy: 0.8692\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.8836 - val_loss: 0.3779 - val_accuracy: 0.8611\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8849 - val_loss: 0.3634 - val_accuracy: 0.8727\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.8916 - val_loss: 0.3701 - val_accuracy: 0.8714\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3137 - accuracy: 0.8856 - val_loss: 0.3647 - val_accuracy: 0.8712\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2947 - accuracy: 0.8906 - val_loss: 0.3609 - val_accuracy: 0.8730\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3014 - accuracy: 0.8864 - val_loss: 0.3575 - val_accuracy: 0.8717\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2982 - accuracy: 0.8937 - val_loss: 0.3537 - val_accuracy: 0.8752\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3026 - accuracy: 0.8911 - val_loss: 0.3603 - val_accuracy: 0.8689\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.8880 - val_loss: 0.3632 - val_accuracy: 0.8728\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2922 - accuracy: 0.8914 - val_loss: 0.3598 - val_accuracy: 0.8678\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2983 - accuracy: 0.8889 - val_loss: 0.3557 - val_accuracy: 0.8723\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.8923 - val_loss: 0.3540 - val_accuracy: 0.8723\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2950 - accuracy: 0.8940 - val_loss: 0.3371 - val_accuracy: 0.8794\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2953 - accuracy: 0.8924 - val_loss: 0.3626 - val_accuracy: 0.8712\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2830 - accuracy: 0.8906 - val_loss: 0.3577 - val_accuracy: 0.8720\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2971 - accuracy: 0.8929 - val_loss: 0.3639 - val_accuracy: 0.8705\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2869 - accuracy: 0.8975 - val_loss: 0.3539 - val_accuracy: 0.8744\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.8904 - val_loss: 0.3786 - val_accuracy: 0.8603\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2942 - accuracy: 0.8921 - val_loss: 0.3534 - val_accuracy: 0.8736\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.8915 - val_loss: 0.3526 - val_accuracy: 0.8745\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2852 - accuracy: 0.8959 - val_loss: 0.3414 - val_accuracy: 0.8752\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2802 - accuracy: 0.8964 - val_loss: 0.3565 - val_accuracy: 0.8719\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2882 - accuracy: 0.8958 - val_loss: 0.3549 - val_accuracy: 0.8753\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2817 - accuracy: 0.8943 - val_loss: 0.3608 - val_accuracy: 0.8686\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.8913 - val_loss: 0.3495 - val_accuracy: 0.8761\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2842 - accuracy: 0.8970 - val_loss: 0.3519 - val_accuracy: 0.8741\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2807 - accuracy: 0.8991 - val_loss: 0.3520 - val_accuracy: 0.8777\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2695 - accuracy: 0.9005 - val_loss: 0.3337 - val_accuracy: 0.8800\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.8974 - val_loss: 0.3461 - val_accuracy: 0.8723\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2824 - accuracy: 0.8948 - val_loss: 0.3504 - val_accuracy: 0.8727\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2836 - accuracy: 0.8963 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2778 - accuracy: 0.8987 - val_loss: 0.3475 - val_accuracy: 0.8737\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.9007 - val_loss: 0.3475 - val_accuracy: 0.8753\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2694 - accuracy: 0.8978 - val_loss: 0.3526 - val_accuracy: 0.8759\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2824 - accuracy: 0.8966 - val_loss: 0.3576 - val_accuracy: 0.8742\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2718 - accuracy: 0.9020 - val_loss: 0.3466 - val_accuracy: 0.8769\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2707 - accuracy: 0.9009 - val_loss: 0.3578 - val_accuracy: 0.8759\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2716 - accuracy: 0.8997 - val_loss: 0.3489 - val_accuracy: 0.8720\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2699 - accuracy: 0.9000 - val_loss: 0.3660 - val_accuracy: 0.8694\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2736 - accuracy: 0.8998 - val_loss: 0.3413 - val_accuracy: 0.8711\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2756 - accuracy: 0.9004 - val_loss: 0.3597 - val_accuracy: 0.8719\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2655 - accuracy: 0.9007 - val_loss: 0.3585 - val_accuracy: 0.8723\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2695 - accuracy: 0.8981 - val_loss: 0.3767 - val_accuracy: 0.8673\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2674 - accuracy: 0.9000 - val_loss: 0.3407 - val_accuracy: 0.8777\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2668 - accuracy: 0.9006 - val_loss: 0.3443 - val_accuracy: 0.8758\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2663 - accuracy: 0.9015 - val_loss: 0.3635 - val_accuracy: 0.8689\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2667 - accuracy: 0.8989 - val_loss: 0.3628 - val_accuracy: 0.8712\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2637 - accuracy: 0.9032 - val_loss: 0.3548 - val_accuracy: 0.8716\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.9004 - val_loss: 0.3368 - val_accuracy: 0.8809\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2589 - accuracy: 0.9070 - val_loss: 0.3535 - val_accuracy: 0.8767\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2621 - accuracy: 0.9030 - val_loss: 0.3469 - val_accuracy: 0.8722\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.9001 - val_loss: 0.3550 - val_accuracy: 0.8786\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.9026 - val_loss: 0.3343 - val_accuracy: 0.8798\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2606 - accuracy: 0.9070 - val_loss: 0.3489 - val_accuracy: 0.8777\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2677 - accuracy: 0.9022 - val_loss: 0.3432 - val_accuracy: 0.8773\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2581 - accuracy: 0.9057 - val_loss: 0.3321 - val_accuracy: 0.8817\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2546 - accuracy: 0.9048 - val_loss: 0.3433 - val_accuracy: 0.8800\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2586 - accuracy: 0.9041 - val_loss: 0.3524 - val_accuracy: 0.8734\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2571 - accuracy: 0.9073 - val_loss: 0.3420 - val_accuracy: 0.8798\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2693 - accuracy: 0.9000 - val_loss: 0.3389 - val_accuracy: 0.8773\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2498 - accuracy: 0.9084 - val_loss: 0.3428 - val_accuracy: 0.8777\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2509 - accuracy: 0.9036 - val_loss: 0.3591 - val_accuracy: 0.8723\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9016 - val_loss: 0.3357 - val_accuracy: 0.8819\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2432 - accuracy: 0.9110 - val_loss: 0.3412 - val_accuracy: 0.8820\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9039 - val_loss: 0.3429 - val_accuracy: 0.8780\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2538 - accuracy: 0.9039 - val_loss: 0.3439 - val_accuracy: 0.8778\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2511 - accuracy: 0.9031 - val_loss: 0.3519 - val_accuracy: 0.8806\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.9103 - val_loss: 0.3306 - val_accuracy: 0.8823\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2565 - accuracy: 0.9066 - val_loss: 0.3379 - val_accuracy: 0.8778\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2595 - accuracy: 0.9035 - val_loss: 0.3486 - val_accuracy: 0.8802\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2462 - accuracy: 0.9060 - val_loss: 0.3377 - val_accuracy: 0.8820\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2531 - accuracy: 0.9072 - val_loss: 0.3392 - val_accuracy: 0.8813\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2457 - accuracy: 0.9103 - val_loss: 0.3441 - val_accuracy: 0.8770\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2506 - accuracy: 0.9078 - val_loss: 0.3387 - val_accuracy: 0.8813\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2474 - accuracy: 0.9110 - val_loss: 0.3410 - val_accuracy: 0.8789\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2368 - accuracy: 0.9118 - val_loss: 0.3358 - val_accuracy: 0.8797\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2489 - accuracy: 0.9077 - val_loss: 0.3538 - val_accuracy: 0.8784\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2481 - accuracy: 0.9095 - val_loss: 0.3518 - val_accuracy: 0.8769\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2549 - accuracy: 0.9075 - val_loss: 0.3677 - val_accuracy: 0.8698\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2417 - accuracy: 0.9081 - val_loss: 0.3579 - val_accuracy: 0.8737\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2508 - accuracy: 0.9070 - val_loss: 0.3501 - val_accuracy: 0.8767\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2431 - accuracy: 0.9115 - val_loss: 0.3484 - val_accuracy: 0.8778\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9127 - val_loss: 0.3585 - val_accuracy: 0.8781\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2497 - accuracy: 0.9067 - val_loss: 0.3459 - val_accuracy: 0.8730\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9099 - val_loss: 0.3497 - val_accuracy: 0.8766\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2441 - accuracy: 0.9110 - val_loss: 0.3414 - val_accuracy: 0.8752\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2372 - accuracy: 0.9137 - val_loss: 0.3444 - val_accuracy: 0.8811\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2370 - accuracy: 0.9123 - val_loss: 0.3177 - val_accuracy: 0.8878\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2484 - accuracy: 0.9082 - val_loss: 0.3455 - val_accuracy: 0.8813\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.9093 - val_loss: 0.3264 - val_accuracy: 0.8833\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2388 - accuracy: 0.9108 - val_loss: 0.3530 - val_accuracy: 0.8820\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2383 - accuracy: 0.9152 - val_loss: 0.3539 - val_accuracy: 0.8759\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2396 - accuracy: 0.9123 - val_loss: 0.3448 - val_accuracy: 0.8778\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.9126 - val_loss: 0.3385 - val_accuracy: 0.8806\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9102 - val_loss: 0.3411 - val_accuracy: 0.8794\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2360 - accuracy: 0.9134 - val_loss: 0.3609 - val_accuracy: 0.8734\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2340 - accuracy: 0.9158 - val_loss: 0.3379 - val_accuracy: 0.8789\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2415 - accuracy: 0.9109 - val_loss: 0.3448 - val_accuracy: 0.8766\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2355 - accuracy: 0.9105 - val_loss: 0.3387 - val_accuracy: 0.8780\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2411 - accuracy: 0.9112 - val_loss: 0.3422 - val_accuracy: 0.8750\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9176 - val_loss: 0.3702 - val_accuracy: 0.8759\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.9123 - val_loss: 0.3205 - val_accuracy: 0.8859\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9112 - val_loss: 0.3521 - val_accuracy: 0.8800\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2310 - accuracy: 0.9110 - val_loss: 0.3475 - val_accuracy: 0.8786\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9177 - val_loss: 0.3697 - val_accuracy: 0.8734\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.9147 - val_loss: 0.3934 - val_accuracy: 0.8655\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2347 - accuracy: 0.9118 - val_loss: 0.3422 - val_accuracy: 0.8794\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2272 - accuracy: 0.9137 - val_loss: 0.3413 - val_accuracy: 0.8852\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2338 - accuracy: 0.9137 - val_loss: 0.3367 - val_accuracy: 0.8855\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2317 - accuracy: 0.9157 - val_loss: 0.3334 - val_accuracy: 0.8809\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2226 - accuracy: 0.9195 - val_loss: 0.3258 - val_accuracy: 0.8833\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2329 - accuracy: 0.9141 - val_loss: 0.3315 - val_accuracy: 0.8830\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.9173 - val_loss: 0.3523 - val_accuracy: 0.8784\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2210 - accuracy: 0.9157 - val_loss: 0.3535 - val_accuracy: 0.8800\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9187 - val_loss: 0.3414 - val_accuracy: 0.8831\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2245 - accuracy: 0.9192 - val_loss: 0.3491 - val_accuracy: 0.8814\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2352 - accuracy: 0.9120 - val_loss: 0.3426 - val_accuracy: 0.8834\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2214 - accuracy: 0.9189 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2164 - accuracy: 0.9199 - val_loss: 0.3385 - val_accuracy: 0.8859\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2274 - accuracy: 0.9181 - val_loss: 0.3372 - val_accuracy: 0.8834\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2281 - accuracy: 0.9174 - val_loss: 0.3406 - val_accuracy: 0.8805\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2231 - accuracy: 0.9176 - val_loss: 0.3478 - val_accuracy: 0.8805\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2143 - accuracy: 0.9198 - val_loss: 0.3397 - val_accuracy: 0.8839\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2238 - accuracy: 0.9159 - val_loss: 0.3317 - val_accuracy: 0.8850\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2279 - accuracy: 0.9175 - val_loss: 0.3530 - val_accuracy: 0.8781\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2299 - accuracy: 0.9129 - val_loss: 0.3385 - val_accuracy: 0.8836\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2134 - accuracy: 0.9218 - val_loss: 0.3417 - val_accuracy: 0.8805\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2160 - accuracy: 0.9182 - val_loss: 0.3479 - val_accuracy: 0.8853\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2238 - accuracy: 0.9172 - val_loss: 0.3362 - val_accuracy: 0.8827\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2210 - accuracy: 0.9198 - val_loss: 0.3393 - val_accuracy: 0.8873\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2260 - accuracy: 0.9142 - val_loss: 0.3389 - val_accuracy: 0.8803\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2167 - accuracy: 0.9216 - val_loss: 0.3384 - val_accuracy: 0.8781\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9180 - val_loss: 0.3450 - val_accuracy: 0.8805\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.9199 - val_loss: 0.3502 - val_accuracy: 0.8802\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2197 - accuracy: 0.9180 - val_loss: 0.3520 - val_accuracy: 0.8795\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2202 - accuracy: 0.9172 - val_loss: 0.3428 - val_accuracy: 0.8819\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9183 - val_loss: 0.3438 - val_accuracy: 0.8839\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9218 - val_loss: 0.3384 - val_accuracy: 0.8794\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9212 - val_loss: 0.3494 - val_accuracy: 0.8792\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2208 - accuracy: 0.9167 - val_loss: 0.3465 - val_accuracy: 0.8811\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2200 - accuracy: 0.9189 - val_loss: 0.3483 - val_accuracy: 0.8836\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2202 - accuracy: 0.9166 - val_loss: 0.3564 - val_accuracy: 0.8784\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9223 - val_loss: 0.3691 - val_accuracy: 0.8734\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2063 - accuracy: 0.9238 - val_loss: 0.3681 - val_accuracy: 0.8752\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2195 - accuracy: 0.9171 - val_loss: 0.3448 - val_accuracy: 0.8830\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9213 - val_loss: 0.3694 - val_accuracy: 0.8745\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.9199 - val_loss: 0.3356 - val_accuracy: 0.8864\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2144 - accuracy: 0.9198 - val_loss: 0.3652 - val_accuracy: 0.8758\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9177 - val_loss: 0.3540 - val_accuracy: 0.8781\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9210 - val_loss: 0.3346 - val_accuracy: 0.8863\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9212 - val_loss: 0.3500 - val_accuracy: 0.8838\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.9213 - val_loss: 0.3400 - val_accuracy: 0.8845\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2161 - accuracy: 0.9210 - val_loss: 0.3563 - val_accuracy: 0.8802\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2200 - accuracy: 0.9180 - val_loss: 0.3495 - val_accuracy: 0.8833\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9210 - val_loss: 0.3603 - val_accuracy: 0.8819\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9202 - val_loss: 0.3409 - val_accuracy: 0.8850\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9258 - val_loss: 0.3501 - val_accuracy: 0.8808\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9248 - val_loss: 0.3431 - val_accuracy: 0.8858\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2110 - accuracy: 0.9213 - val_loss: 0.3280 - val_accuracy: 0.8878\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2050 - accuracy: 0.9222 - val_loss: 0.3400 - val_accuracy: 0.8869\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9260 - val_loss: 0.3563 - val_accuracy: 0.8797\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2075 - accuracy: 0.9254 - val_loss: 0.3564 - val_accuracy: 0.8794\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9234 - val_loss: 0.3471 - val_accuracy: 0.8838\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9200 - val_loss: 0.3567 - val_accuracy: 0.8822\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9227 - val_loss: 0.3550 - val_accuracy: 0.8806\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2024 - accuracy: 0.9280 - val_loss: 0.3596 - val_accuracy: 0.8786\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9235 - val_loss: 0.3441 - val_accuracy: 0.8869\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2120 - accuracy: 0.9212 - val_loss: 0.3499 - val_accuracy: 0.8775\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1965 - accuracy: 0.9264 - val_loss: 0.3481 - val_accuracy: 0.8798\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9230 - val_loss: 0.3583 - val_accuracy: 0.8803\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9256 - val_loss: 0.3405 - val_accuracy: 0.8861\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9273 - val_loss: 0.3445 - val_accuracy: 0.8808\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9213 - val_loss: 0.3481 - val_accuracy: 0.8803\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2003 - accuracy: 0.9258 - val_loss: 0.3312 - val_accuracy: 0.8859\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9242 - val_loss: 0.3295 - val_accuracy: 0.8903\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2074 - accuracy: 0.9256 - val_loss: 0.3703 - val_accuracy: 0.8736\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9235 - val_loss: 0.3645 - val_accuracy: 0.8831\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1972 - accuracy: 0.9276 - val_loss: 0.3470 - val_accuracy: 0.8813\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1983 - accuracy: 0.9273 - val_loss: 0.3439 - val_accuracy: 0.8861\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9254 - val_loss: 0.3607 - val_accuracy: 0.8809\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9262 - val_loss: 0.3579 - val_accuracy: 0.8820\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9245 - val_loss: 0.3549 - val_accuracy: 0.8806\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.1991 - accuracy: 0.9270 - val_loss: 0.3557 - val_accuracy: 0.8789\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 0s 5ms/step - loss: 0.1943 - accuracy: 0.9268 - val_loss: 0.3548 - val_accuracy: 0.8783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXrIw3msPGK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddde5211-9bf0-477e-f448-329651595e2b"
      },
      "source": [
        "loss_value,acc_value=model.evaluate(test_dataset,steps=50,verbose=0)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy  0.878125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dc-PvRSlKLD",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of DNN is 87%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfTL_5kPsl4j",
        "colab_type": "text"
      },
      "source": [
        "### CNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTC80g1d0dML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x_cn, train_y_cn), (test_x_cn, test_y_cn) = fashion_mnist.load_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6YEDtOy0SQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_cn = train_x_cn.reshape(60000,28,28,1)\n",
        "test_x_cn = test_x_cn.reshape(10000,28,28,1)\n",
        "\n",
        "train_y_cn= to_categorical(train_y_cn)\n",
        "test_y_cn= to_categorical(test_y_cn)\n",
        "\n",
        "train_x_cn =tf.image.convert_image_dtype(train_x_cn, tf.float32)\n",
        "train_x_cn=train_x_cn/255\n",
        "test_x_cn =tf.image.convert_image_dtype(test_x_cn, tf.float32)\n",
        "test_x_cn = test_x_cn/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-8mJvJS1KeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_cn = tf.data.Dataset.from_tensor_slices((train_x_cn, train_y_cn))\n",
        "train_dataset_cn = train_dataset_cn.shuffle(buffer_size=10000).batch(batch_size=128).repeat()\n",
        "test_dataset_cn = tf.data.Dataset.from_tensor_slices((test_x_cn, test_y_cn))\n",
        "test_dataset_cn = test_dataset_cn.shuffle(buffer_size=10000).batch(batch_size=128).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAhRVa_kLg_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn = Sequential()\n",
        "model_cnn.add(Convolution2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)))\n",
        "model_cnn.add(Convolution2D(32, kernel_size=3, activation='relu'))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sW8o9pqquux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1943712b-16c5-4530-fbec-0db1c6249525"
      },
      "source": [
        "Epochs=250\n",
        "STEPS_PER_EPOCH=100\n",
        "\n",
        "history=model_cnn.fit(train_dataset_cn, epochs=Epochs,validation_data=test_dataset_cn,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.5659 - accuracy: 0.4831 - val_loss: 0.8475 - val_accuracy: 0.6888\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.7447 - accuracy: 0.7312 - val_loss: 0.6875 - val_accuracy: 0.7459\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.6379 - accuracy: 0.7680 - val_loss: 0.6496 - val_accuracy: 0.7517\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5904 - accuracy: 0.7820 - val_loss: 0.6108 - val_accuracy: 0.7708\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.5741 - accuracy: 0.7877 - val_loss: 0.5848 - val_accuracy: 0.7861\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5537 - accuracy: 0.7985 - val_loss: 0.5707 - val_accuracy: 0.7942\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5415 - accuracy: 0.8028 - val_loss: 0.5481 - val_accuracy: 0.8002\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5139 - accuracy: 0.8161 - val_loss: 0.5395 - val_accuracy: 0.8014\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5184 - accuracy: 0.8098 - val_loss: 0.5442 - val_accuracy: 0.7975\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4973 - accuracy: 0.8170 - val_loss: 0.5329 - val_accuracy: 0.8075\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.5012 - accuracy: 0.8194 - val_loss: 0.5265 - val_accuracy: 0.8103\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4765 - accuracy: 0.8261 - val_loss: 0.4985 - val_accuracy: 0.8247\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4829 - accuracy: 0.8283 - val_loss: 0.5170 - val_accuracy: 0.8136\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4648 - accuracy: 0.8322 - val_loss: 0.5028 - val_accuracy: 0.8202\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4782 - accuracy: 0.8239 - val_loss: 0.5027 - val_accuracy: 0.8189\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4643 - accuracy: 0.8319 - val_loss: 0.4723 - val_accuracy: 0.8309\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4428 - accuracy: 0.8412 - val_loss: 0.5190 - val_accuracy: 0.8087\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4634 - accuracy: 0.8353 - val_loss: 0.4732 - val_accuracy: 0.8294\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4504 - accuracy: 0.8399 - val_loss: 0.4796 - val_accuracy: 0.8283\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4468 - accuracy: 0.8394 - val_loss: 0.4798 - val_accuracy: 0.8319\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4344 - accuracy: 0.8473 - val_loss: 0.4699 - val_accuracy: 0.8391\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4436 - accuracy: 0.8420 - val_loss: 0.4719 - val_accuracy: 0.8292\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4397 - accuracy: 0.8434 - val_loss: 0.4758 - val_accuracy: 0.8267\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4370 - accuracy: 0.8419 - val_loss: 0.4646 - val_accuracy: 0.8256\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4329 - accuracy: 0.8399 - val_loss: 0.4629 - val_accuracy: 0.8369\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4376 - accuracy: 0.8459 - val_loss: 0.4556 - val_accuracy: 0.8358\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4204 - accuracy: 0.8555 - val_loss: 0.4589 - val_accuracy: 0.8366\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4289 - accuracy: 0.8432 - val_loss: 0.4669 - val_accuracy: 0.8352\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4257 - accuracy: 0.8490 - val_loss: 0.4419 - val_accuracy: 0.8414\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4091 - accuracy: 0.8506 - val_loss: 0.4605 - val_accuracy: 0.8300\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4162 - accuracy: 0.8530 - val_loss: 0.4444 - val_accuracy: 0.8439\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4133 - accuracy: 0.8503 - val_loss: 0.4481 - val_accuracy: 0.8494\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4235 - accuracy: 0.8493 - val_loss: 0.4492 - val_accuracy: 0.8433\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4125 - accuracy: 0.8517 - val_loss: 0.4580 - val_accuracy: 0.8334\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4130 - accuracy: 0.8533 - val_loss: 0.4550 - val_accuracy: 0.8389\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3934 - accuracy: 0.8598 - val_loss: 0.4415 - val_accuracy: 0.8470\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3977 - accuracy: 0.8607 - val_loss: 0.4319 - val_accuracy: 0.8516\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4053 - accuracy: 0.8521 - val_loss: 0.4524 - val_accuracy: 0.8384\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4000 - accuracy: 0.8554 - val_loss: 0.4460 - val_accuracy: 0.8403\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4001 - accuracy: 0.8591 - val_loss: 0.4328 - val_accuracy: 0.8530\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3881 - accuracy: 0.8632 - val_loss: 0.4186 - val_accuracy: 0.8600\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.4009 - accuracy: 0.8575 - val_loss: 0.4262 - val_accuracy: 0.8500\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3960 - accuracy: 0.8585 - val_loss: 0.4317 - val_accuracy: 0.8448\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3839 - accuracy: 0.8587 - val_loss: 0.4283 - val_accuracy: 0.8473\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3997 - accuracy: 0.8593 - val_loss: 0.4235 - val_accuracy: 0.8523\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3877 - accuracy: 0.8621 - val_loss: 0.4305 - val_accuracy: 0.8469\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3810 - accuracy: 0.8609 - val_loss: 0.4299 - val_accuracy: 0.8439\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3914 - accuracy: 0.8568 - val_loss: 0.4098 - val_accuracy: 0.8564\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3855 - accuracy: 0.8642 - val_loss: 0.4197 - val_accuracy: 0.8519\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3824 - accuracy: 0.8634 - val_loss: 0.4229 - val_accuracy: 0.8481\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3893 - accuracy: 0.8617 - val_loss: 0.4040 - val_accuracy: 0.8566\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3716 - accuracy: 0.8665 - val_loss: 0.4193 - val_accuracy: 0.8495\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3827 - accuracy: 0.8585 - val_loss: 0.4182 - val_accuracy: 0.8542\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3734 - accuracy: 0.8709 - val_loss: 0.3990 - val_accuracy: 0.8558\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3671 - accuracy: 0.8690 - val_loss: 0.4060 - val_accuracy: 0.8589\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3735 - accuracy: 0.8677 - val_loss: 0.4141 - val_accuracy: 0.8537\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3705 - accuracy: 0.8651 - val_loss: 0.4174 - val_accuracy: 0.8448\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3694 - accuracy: 0.8662 - val_loss: 0.4149 - val_accuracy: 0.8509\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.3655 - accuracy: 0.8755 - val_loss: 0.4085 - val_accuracy: 0.8523\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3754 - accuracy: 0.8670 - val_loss: 0.3830 - val_accuracy: 0.8644\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3615 - accuracy: 0.8698 - val_loss: 0.3998 - val_accuracy: 0.8602\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3602 - accuracy: 0.8688 - val_loss: 0.4126 - val_accuracy: 0.8484\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3666 - accuracy: 0.8697 - val_loss: 0.3958 - val_accuracy: 0.8553\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3658 - accuracy: 0.8687 - val_loss: 0.3963 - val_accuracy: 0.8614\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3633 - accuracy: 0.8708 - val_loss: 0.4150 - val_accuracy: 0.8544\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3548 - accuracy: 0.8745 - val_loss: 0.4004 - val_accuracy: 0.8614\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3575 - accuracy: 0.8665 - val_loss: 0.3864 - val_accuracy: 0.8633\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3502 - accuracy: 0.8764 - val_loss: 0.3788 - val_accuracy: 0.8633\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3493 - accuracy: 0.8779 - val_loss: 0.4099 - val_accuracy: 0.8561\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3540 - accuracy: 0.8705 - val_loss: 0.4023 - val_accuracy: 0.8509\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3504 - accuracy: 0.8717 - val_loss: 0.3979 - val_accuracy: 0.8581\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3520 - accuracy: 0.8714 - val_loss: 0.3896 - val_accuracy: 0.8619\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3491 - accuracy: 0.8771 - val_loss: 0.3852 - val_accuracy: 0.8623\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3488 - accuracy: 0.8754 - val_loss: 0.3881 - val_accuracy: 0.8612\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3378 - accuracy: 0.8758 - val_loss: 0.3946 - val_accuracy: 0.8594\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3467 - accuracy: 0.8722 - val_loss: 0.3804 - val_accuracy: 0.8600\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3414 - accuracy: 0.8745 - val_loss: 0.3972 - val_accuracy: 0.8587\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3402 - accuracy: 0.8802 - val_loss: 0.3815 - val_accuracy: 0.8647\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3356 - accuracy: 0.8770 - val_loss: 0.3885 - val_accuracy: 0.8622\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3327 - accuracy: 0.8804 - val_loss: 0.3784 - val_accuracy: 0.8625\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3256 - accuracy: 0.8806 - val_loss: 0.3809 - val_accuracy: 0.8636\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3342 - accuracy: 0.8813 - val_loss: 0.3805 - val_accuracy: 0.8662\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3295 - accuracy: 0.8807 - val_loss: 0.3892 - val_accuracy: 0.8623\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3299 - accuracy: 0.8807 - val_loss: 0.3723 - val_accuracy: 0.8708\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3330 - accuracy: 0.8799 - val_loss: 0.3591 - val_accuracy: 0.8717\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3317 - accuracy: 0.8787 - val_loss: 0.3734 - val_accuracy: 0.8641\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3139 - accuracy: 0.8891 - val_loss: 0.3613 - val_accuracy: 0.8700\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3181 - accuracy: 0.8863 - val_loss: 0.3585 - val_accuracy: 0.8722\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3176 - accuracy: 0.8834 - val_loss: 0.3606 - val_accuracy: 0.8708\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3160 - accuracy: 0.8842 - val_loss: 0.3841 - val_accuracy: 0.8623\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3099 - accuracy: 0.8881 - val_loss: 0.3629 - val_accuracy: 0.8684\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3252 - accuracy: 0.8882 - val_loss: 0.3512 - val_accuracy: 0.8748\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3020 - accuracy: 0.8899 - val_loss: 0.3651 - val_accuracy: 0.8661\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3108 - accuracy: 0.8874 - val_loss: 0.3589 - val_accuracy: 0.8723\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2885 - accuracy: 0.8912 - val_loss: 0.3615 - val_accuracy: 0.8703\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3131 - accuracy: 0.8869 - val_loss: 0.3434 - val_accuracy: 0.8773\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3007 - accuracy: 0.8931 - val_loss: 0.3407 - val_accuracy: 0.8769\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.3029 - accuracy: 0.8895 - val_loss: 0.3408 - val_accuracy: 0.8759\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2789 - accuracy: 0.8974 - val_loss: 0.3463 - val_accuracy: 0.8802\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2929 - accuracy: 0.8949 - val_loss: 0.3432 - val_accuracy: 0.8773\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2983 - accuracy: 0.8919 - val_loss: 0.3305 - val_accuracy: 0.8827\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2917 - accuracy: 0.8977 - val_loss: 0.3439 - val_accuracy: 0.8798\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2840 - accuracy: 0.8970 - val_loss: 0.3633 - val_accuracy: 0.8753\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2927 - accuracy: 0.8946 - val_loss: 0.3341 - val_accuracy: 0.8817\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2836 - accuracy: 0.8932 - val_loss: 0.3459 - val_accuracy: 0.8788\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.2825 - accuracy: 0.9002 - val_loss: 0.3247 - val_accuracy: 0.8822\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2774 - accuracy: 0.9002 - val_loss: 0.3303 - val_accuracy: 0.8844\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2807 - accuracy: 0.8979 - val_loss: 0.3453 - val_accuracy: 0.8755\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2715 - accuracy: 0.8991 - val_loss: 0.3438 - val_accuracy: 0.8777\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2768 - accuracy: 0.9003 - val_loss: 0.3259 - val_accuracy: 0.8850\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2849 - accuracy: 0.8959 - val_loss: 0.3319 - val_accuracy: 0.8861\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2703 - accuracy: 0.9017 - val_loss: 0.3269 - val_accuracy: 0.8836\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2679 - accuracy: 0.9029 - val_loss: 0.3271 - val_accuracy: 0.8863\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2647 - accuracy: 0.9017 - val_loss: 0.3229 - val_accuracy: 0.8845\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2696 - accuracy: 0.9023 - val_loss: 0.3246 - val_accuracy: 0.8884\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2690 - accuracy: 0.9024 - val_loss: 0.3296 - val_accuracy: 0.8875\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2667 - accuracy: 0.9042 - val_loss: 0.3291 - val_accuracy: 0.8864\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2634 - accuracy: 0.9023 - val_loss: 0.3354 - val_accuracy: 0.8838\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2600 - accuracy: 0.9065 - val_loss: 0.3390 - val_accuracy: 0.8775\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2654 - accuracy: 0.9020 - val_loss: 0.3286 - val_accuracy: 0.8859\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2697 - accuracy: 0.9016 - val_loss: 0.3321 - val_accuracy: 0.8800\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2622 - accuracy: 0.9047 - val_loss: 0.3238 - val_accuracy: 0.8891\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2572 - accuracy: 0.9073 - val_loss: 0.3071 - val_accuracy: 0.8928\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2619 - accuracy: 0.9047 - val_loss: 0.3208 - val_accuracy: 0.8834\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2495 - accuracy: 0.9083 - val_loss: 0.3288 - val_accuracy: 0.8869\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2625 - accuracy: 0.9034 - val_loss: 0.3189 - val_accuracy: 0.8877\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2413 - accuracy: 0.9121 - val_loss: 0.3312 - val_accuracy: 0.8908\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2592 - accuracy: 0.9041 - val_loss: 0.3100 - val_accuracy: 0.8916\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2516 - accuracy: 0.9066 - val_loss: 0.3158 - val_accuracy: 0.8941\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2556 - accuracy: 0.9084 - val_loss: 0.3338 - val_accuracy: 0.8863\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2437 - accuracy: 0.9102 - val_loss: 0.3127 - val_accuracy: 0.8886\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2445 - accuracy: 0.9096 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2442 - accuracy: 0.9093 - val_loss: 0.3198 - val_accuracy: 0.8888\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.3077 - val_accuracy: 0.8933\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2417 - accuracy: 0.9103 - val_loss: 0.3168 - val_accuracy: 0.8919\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2340 - accuracy: 0.9132 - val_loss: 0.3288 - val_accuracy: 0.8827\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2343 - accuracy: 0.9139 - val_loss: 0.3137 - val_accuracy: 0.8919\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2438 - accuracy: 0.9116 - val_loss: 0.3162 - val_accuracy: 0.8898\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2416 - accuracy: 0.9132 - val_loss: 0.3277 - val_accuracy: 0.8883\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2375 - accuracy: 0.9140 - val_loss: 0.3034 - val_accuracy: 0.8938\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2379 - accuracy: 0.9139 - val_loss: 0.3287 - val_accuracy: 0.8895\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2306 - accuracy: 0.9127 - val_loss: 0.3202 - val_accuracy: 0.8906\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2412 - accuracy: 0.9117 - val_loss: 0.3128 - val_accuracy: 0.8908\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2354 - accuracy: 0.9146 - val_loss: 0.3051 - val_accuracy: 0.8958\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2369 - accuracy: 0.9127 - val_loss: 0.3025 - val_accuracy: 0.8939\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2306 - accuracy: 0.9164 - val_loss: 0.3230 - val_accuracy: 0.8897\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2358 - accuracy: 0.9159 - val_loss: 0.3087 - val_accuracy: 0.8959\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2340 - accuracy: 0.9155 - val_loss: 0.3130 - val_accuracy: 0.8930\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2225 - accuracy: 0.9209 - val_loss: 0.3136 - val_accuracy: 0.8886\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2332 - accuracy: 0.9120 - val_loss: 0.3082 - val_accuracy: 0.8925\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2191 - accuracy: 0.9175 - val_loss: 0.3069 - val_accuracy: 0.8948\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2302 - accuracy: 0.9160 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2194 - accuracy: 0.9237 - val_loss: 0.3147 - val_accuracy: 0.8841\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2323 - accuracy: 0.9145 - val_loss: 0.3180 - val_accuracy: 0.8917\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2218 - accuracy: 0.9167 - val_loss: 0.3071 - val_accuracy: 0.8931\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2204 - accuracy: 0.9197 - val_loss: 0.3213 - val_accuracy: 0.8927\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2283 - accuracy: 0.9152 - val_loss: 0.3114 - val_accuracy: 0.8938\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2197 - accuracy: 0.9204 - val_loss: 0.3007 - val_accuracy: 0.8950\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2176 - accuracy: 0.9194 - val_loss: 0.3163 - val_accuracy: 0.8903\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2158 - accuracy: 0.9207 - val_loss: 0.3045 - val_accuracy: 0.8995\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3112 - val_accuracy: 0.8970\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2185 - accuracy: 0.9195 - val_loss: 0.3055 - val_accuracy: 0.8933\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2206 - accuracy: 0.9178 - val_loss: 0.3126 - val_accuracy: 0.8978\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2193 - accuracy: 0.9209 - val_loss: 0.3098 - val_accuracy: 0.8973\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2083 - accuracy: 0.9225 - val_loss: 0.3143 - val_accuracy: 0.8947\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2196 - accuracy: 0.9214 - val_loss: 0.3048 - val_accuracy: 0.8972\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2163 - accuracy: 0.9241 - val_loss: 0.2824 - val_accuracy: 0.9011\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2044 - accuracy: 0.9248 - val_loss: 0.3101 - val_accuracy: 0.8963\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2105 - accuracy: 0.9236 - val_loss: 0.3159 - val_accuracy: 0.8956\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2103 - accuracy: 0.9240 - val_loss: 0.2982 - val_accuracy: 0.8984\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2117 - accuracy: 0.9212 - val_loss: 0.3049 - val_accuracy: 0.8970\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2098 - accuracy: 0.9254 - val_loss: 0.2920 - val_accuracy: 0.8991\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2102 - accuracy: 0.9230 - val_loss: 0.3080 - val_accuracy: 0.8981\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2045 - accuracy: 0.9236 - val_loss: 0.3128 - val_accuracy: 0.8956\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2109 - accuracy: 0.9239 - val_loss: 0.3060 - val_accuracy: 0.8955\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2099 - accuracy: 0.9248 - val_loss: 0.3091 - val_accuracy: 0.8989\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2013 - accuracy: 0.9266 - val_loss: 0.3138 - val_accuracy: 0.8941\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2041 - accuracy: 0.9240 - val_loss: 0.3373 - val_accuracy: 0.8877\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2049 - accuracy: 0.9247 - val_loss: 0.3138 - val_accuracy: 0.8934\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2028 - accuracy: 0.9254 - val_loss: 0.3011 - val_accuracy: 0.8973\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2054 - accuracy: 0.9266 - val_loss: 0.3145 - val_accuracy: 0.8922\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2015 - accuracy: 0.9257 - val_loss: 0.3014 - val_accuracy: 0.8997\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1985 - accuracy: 0.9261 - val_loss: 0.3112 - val_accuracy: 0.8986\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2019 - accuracy: 0.9267 - val_loss: 0.3125 - val_accuracy: 0.8970\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2023 - accuracy: 0.9264 - val_loss: 0.2997 - val_accuracy: 0.8952\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1986 - accuracy: 0.9258 - val_loss: 0.2997 - val_accuracy: 0.8959\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1950 - accuracy: 0.9277 - val_loss: 0.3048 - val_accuracy: 0.9008\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1897 - accuracy: 0.9297 - val_loss: 0.3153 - val_accuracy: 0.8931\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2009 - accuracy: 0.9256 - val_loss: 0.3084 - val_accuracy: 0.8989\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2014 - accuracy: 0.9280 - val_loss: 0.3135 - val_accuracy: 0.8925\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.2010 - accuracy: 0.9263 - val_loss: 0.3093 - val_accuracy: 0.8955\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1931 - accuracy: 0.9263 - val_loss: 0.3147 - val_accuracy: 0.8984\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1922 - accuracy: 0.9305 - val_loss: 0.3042 - val_accuracy: 0.8975\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1910 - accuracy: 0.9308 - val_loss: 0.3178 - val_accuracy: 0.8973\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1996 - accuracy: 0.9273 - val_loss: 0.3104 - val_accuracy: 0.8919\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1922 - accuracy: 0.9300 - val_loss: 0.3046 - val_accuracy: 0.8938\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1899 - accuracy: 0.9294 - val_loss: 0.3070 - val_accuracy: 0.8942\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1946 - accuracy: 0.9290 - val_loss: 0.3030 - val_accuracy: 0.8978\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1871 - accuracy: 0.9321 - val_loss: 0.2983 - val_accuracy: 0.9003\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1952 - accuracy: 0.9295 - val_loss: 0.3291 - val_accuracy: 0.8909\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1826 - accuracy: 0.9338 - val_loss: 0.2934 - val_accuracy: 0.9008\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1842 - accuracy: 0.9317 - val_loss: 0.3181 - val_accuracy: 0.9006\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1933 - accuracy: 0.9310 - val_loss: 0.3239 - val_accuracy: 0.8953\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1937 - accuracy: 0.9287 - val_loss: 0.3053 - val_accuracy: 0.8950\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1836 - accuracy: 0.9356 - val_loss: 0.3024 - val_accuracy: 0.8964\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1893 - accuracy: 0.9312 - val_loss: 0.3129 - val_accuracy: 0.8963\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 0.3076 - val_accuracy: 0.8973\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1809 - accuracy: 0.9314 - val_loss: 0.3045 - val_accuracy: 0.9028\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1934 - accuracy: 0.9316 - val_loss: 0.3070 - val_accuracy: 0.9066\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1790 - accuracy: 0.9361 - val_loss: 0.3050 - val_accuracy: 0.9006\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1806 - accuracy: 0.9334 - val_loss: 0.3106 - val_accuracy: 0.9005\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1805 - accuracy: 0.9337 - val_loss: 0.3173 - val_accuracy: 0.9005\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1851 - accuracy: 0.9328 - val_loss: 0.3101 - val_accuracy: 0.8995\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1772 - accuracy: 0.9373 - val_loss: 0.2958 - val_accuracy: 0.9019\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 0.3236 - val_accuracy: 0.8959\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1800 - accuracy: 0.9332 - val_loss: 0.3026 - val_accuracy: 0.9016\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1761 - accuracy: 0.9351 - val_loss: 0.3296 - val_accuracy: 0.8941\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1804 - accuracy: 0.9348 - val_loss: 0.3215 - val_accuracy: 0.9000\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1782 - accuracy: 0.9370 - val_loss: 0.3104 - val_accuracy: 0.8927\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1735 - accuracy: 0.9373 - val_loss: 0.3172 - val_accuracy: 0.8991\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1774 - accuracy: 0.9317 - val_loss: 0.3141 - val_accuracy: 0.8984\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1781 - accuracy: 0.9352 - val_loss: 0.3202 - val_accuracy: 0.8984\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1779 - accuracy: 0.9358 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1748 - accuracy: 0.9366 - val_loss: 0.3054 - val_accuracy: 0.9036\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 2s 15ms/step - loss: 0.1663 - accuracy: 0.9375 - val_loss: 0.3252 - val_accuracy: 0.8969\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1718 - accuracy: 0.9362 - val_loss: 0.3275 - val_accuracy: 0.8963\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1764 - accuracy: 0.9371 - val_loss: 0.3116 - val_accuracy: 0.9020\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1795 - accuracy: 0.9367 - val_loss: 0.3068 - val_accuracy: 0.9009\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1664 - accuracy: 0.9372 - val_loss: 0.3089 - val_accuracy: 0.9027\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1677 - accuracy: 0.9389 - val_loss: 0.3124 - val_accuracy: 0.9027\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1712 - accuracy: 0.9363 - val_loss: 0.3197 - val_accuracy: 0.8983\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1775 - accuracy: 0.9348 - val_loss: 0.3310 - val_accuracy: 0.8955\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1733 - accuracy: 0.9368 - val_loss: 0.3084 - val_accuracy: 0.9000\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1722 - accuracy: 0.9362 - val_loss: 0.3208 - val_accuracy: 0.8977\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1588 - accuracy: 0.9424 - val_loss: 0.3106 - val_accuracy: 0.9008\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1678 - accuracy: 0.9390 - val_loss: 0.3061 - val_accuracy: 0.9041\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1734 - accuracy: 0.9362 - val_loss: 0.3163 - val_accuracy: 0.8991\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1667 - accuracy: 0.9405 - val_loss: 0.3241 - val_accuracy: 0.8945\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1615 - accuracy: 0.9391 - val_loss: 0.3155 - val_accuracy: 0.8972\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1630 - accuracy: 0.9416 - val_loss: 0.3071 - val_accuracy: 0.9025\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1736 - accuracy: 0.9356 - val_loss: 0.3150 - val_accuracy: 0.8975\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1644 - accuracy: 0.9399 - val_loss: 0.3255 - val_accuracy: 0.8972\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1596 - accuracy: 0.9435 - val_loss: 0.3229 - val_accuracy: 0.8972\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1663 - accuracy: 0.9372 - val_loss: 0.3144 - val_accuracy: 0.9006\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1645 - accuracy: 0.9386 - val_loss: 0.3169 - val_accuracy: 0.9030\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1639 - accuracy: 0.9390 - val_loss: 0.3364 - val_accuracy: 0.8966\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 0.1691 - accuracy: 0.9391 - val_loss: 0.3349 - val_accuracy: 0.8944\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1602 - accuracy: 0.9433 - val_loss: 0.3258 - val_accuracy: 0.8994\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1532 - accuracy: 0.9429 - val_loss: 0.3187 - val_accuracy: 0.9027\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 0.1591 - accuracy: 0.9417 - val_loss: 0.3308 - val_accuracy: 0.8973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YphCWxoQ_Me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed613639-9ed3-4d83-9154-c26be80c492c"
      },
      "source": [
        "loss_value,acc_value=model_cnn.evaluate(test_dataset_cn,steps=50,verbose=0)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy  0.8987500071525574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OequUaLlTUq",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of CNN is 89%. Slightly higher than DNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbhr44DnMbKZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Data augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv5SF6OD8ZIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x_cn, train_y_cn), (test_x_cn, test_y_cn) = fashion_mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zT7AMM08g88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_cn = train_x_cn.reshape(60000,28,28,1)\n",
        "test_x_cn = test_x_cn.reshape(10000,28,28,1)\n",
        "\n",
        "train_y_cn= to_categorical(train_y_cn)\n",
        "test_y_cn= to_categorical(test_y_cn)\n",
        "\n",
        "train_x_cn =tf.image.convert_image_dtype(train_x_cn, tf.float32)\n",
        "train_x_cn=train_x_cn/255\n",
        "test_x_cn =tf.image.convert_image_dtype(test_x_cn, tf.float32)\n",
        "test_x_cn = test_x_cn/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBtJ_oaY8oza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_cn = tf.data.Dataset.from_tensor_slices((train_x_cn, train_y_cn))\n",
        "train_dataset_cn = train_dataset_cn.shuffle(buffer_size=10000).batch(batch_size=128).repeat()\n",
        "test_dataset_cn = tf.data.Dataset.from_tensor_slices((test_x_cn, test_y_cn))\n",
        "test_dataset_cn = test_dataset_cn.shuffle(buffer_size=10000).batch(batch_size=128).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yII3c6Cfqw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19c46734-2dd6-4bf3-d69f-60bd773a936d"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B0gJYsXf5_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator( \n",
        "        rotation_range=10,        # randomly rotate between 0-rotation_range angle\n",
        "        width_shift_range=0.2,    # randomly shift horizontally by this much\n",
        "        height_shift_range=0.2,   # randomly shift vertically by this muc          \n",
        "        zoom_range=0.2,           # randomly zoom (80% - 120%)\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'       # fill any pixels lost in xform with nearest\n",
        "    )\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YQjfU07VhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen= ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCqT2Sye7d81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen= train_datagen.flow(train_x_cn, train_y_cn, batch_size=128)\n",
        "test_gen= datagen.flow(test_x_cn, test_y_cn, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6YGO12iV-ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DA = Sequential()\n",
        "model_DA.add(Convolution2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)))\n",
        "model_DA.add(Convolution2D(32, kernel_size=3, activation='relu'))\n",
        "model_DA.add(Flatten())\n",
        "model_DA.add(Dense(10, activation='softmax'))\n",
        "model_DA.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqeNFxmtWJy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1db8b93d-5aea-4cc5-c8bf-6ec6bc0104db"
      },
      "source": [
        "Epochs=250\n",
        "STEPS_PER_EPOCH=100\n",
        "\n",
        "history=model_DA.fit(train_gen, epochs=Epochs,validation_data=test_gen,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.2377 - accuracy: 0.5547 - val_loss: 1.0217 - val_accuracy: 0.6381\n",
            "Epoch 2/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.2355 - accuracy: 0.5546 - val_loss: 1.0739 - val_accuracy: 0.6167\n",
            "Epoch 3/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.2167 - accuracy: 0.5568 - val_loss: 1.0042 - val_accuracy: 0.6544\n",
            "Epoch 4/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.2033 - accuracy: 0.5638 - val_loss: 1.0183 - val_accuracy: 0.6442\n",
            "Epoch 5/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1972 - accuracy: 0.5661 - val_loss: 0.9972 - val_accuracy: 0.6644\n",
            "Epoch 6/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.2021 - accuracy: 0.5654 - val_loss: 1.0094 - val_accuracy: 0.6433\n",
            "Epoch 7/250\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 1.1875 - accuracy: 0.5759 - val_loss: 0.9832 - val_accuracy: 0.6492\n",
            "Epoch 8/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.1723 - accuracy: 0.5755 - val_loss: 0.9739 - val_accuracy: 0.6581\n",
            "Epoch 9/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1778 - accuracy: 0.5736 - val_loss: 0.9586 - val_accuracy: 0.6411\n",
            "Epoch 10/250\n",
            "100/100 [==============================] - 5s 45ms/step - loss: 1.1638 - accuracy: 0.5795 - val_loss: 0.9464 - val_accuracy: 0.6728\n",
            "Epoch 11/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1700 - accuracy: 0.5817 - val_loss: 0.9397 - val_accuracy: 0.6573\n",
            "Epoch 12/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1660 - accuracy: 0.5753 - val_loss: 0.9597 - val_accuracy: 0.6658\n",
            "Epoch 13/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1558 - accuracy: 0.5778 - val_loss: 0.9613 - val_accuracy: 0.6594\n",
            "Epoch 14/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1458 - accuracy: 0.5818 - val_loss: 0.9408 - val_accuracy: 0.6681\n",
            "Epoch 15/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1522 - accuracy: 0.5863 - val_loss: 0.9787 - val_accuracy: 0.6455\n",
            "Epoch 16/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1534 - accuracy: 0.5752 - val_loss: 0.9529 - val_accuracy: 0.6475\n",
            "Epoch 17/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1288 - accuracy: 0.5912 - val_loss: 0.9495 - val_accuracy: 0.6356\n",
            "Epoch 18/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1248 - accuracy: 0.5858 - val_loss: 0.9294 - val_accuracy: 0.6686\n",
            "Epoch 19/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1303 - accuracy: 0.5901 - val_loss: 0.9399 - val_accuracy: 0.6497\n",
            "Epoch 20/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1393 - accuracy: 0.5785 - val_loss: 0.9460 - val_accuracy: 0.6555\n",
            "Epoch 21/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1083 - accuracy: 0.5994 - val_loss: 0.9388 - val_accuracy: 0.6542\n",
            "Epoch 22/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1188 - accuracy: 0.5916 - val_loss: 0.9356 - val_accuracy: 0.6562\n",
            "Epoch 23/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.1304 - accuracy: 0.5901 - val_loss: 0.9031 - val_accuracy: 0.6734\n",
            "Epoch 24/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1314 - accuracy: 0.5877 - val_loss: 0.9211 - val_accuracy: 0.6722\n",
            "Epoch 25/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1046 - accuracy: 0.6034 - val_loss: 0.9237 - val_accuracy: 0.6789\n",
            "Epoch 26/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0899 - accuracy: 0.5979 - val_loss: 0.9096 - val_accuracy: 0.6614\n",
            "Epoch 27/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1136 - accuracy: 0.5942 - val_loss: 0.9523 - val_accuracy: 0.6705\n",
            "Epoch 28/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0953 - accuracy: 0.6056 - val_loss: 0.9754 - val_accuracy: 0.6459\n",
            "Epoch 29/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1221 - accuracy: 0.5938 - val_loss: 0.9206 - val_accuracy: 0.6677\n",
            "Epoch 30/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.1167 - accuracy: 0.5897 - val_loss: 0.8977 - val_accuracy: 0.6717\n",
            "Epoch 31/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1061 - accuracy: 0.6002 - val_loss: 0.9453 - val_accuracy: 0.6630\n",
            "Epoch 32/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1025 - accuracy: 0.5946 - val_loss: 0.9194 - val_accuracy: 0.6480\n",
            "Epoch 33/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1069 - accuracy: 0.5974 - val_loss: 0.9221 - val_accuracy: 0.6569\n",
            "Epoch 34/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.1058 - accuracy: 0.5949 - val_loss: 0.8912 - val_accuracy: 0.6803\n",
            "Epoch 35/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0913 - accuracy: 0.6070 - val_loss: 0.8869 - val_accuracy: 0.6662\n",
            "Epoch 36/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0865 - accuracy: 0.6058 - val_loss: 0.8938 - val_accuracy: 0.6681\n",
            "Epoch 37/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0869 - accuracy: 0.6020 - val_loss: 0.9318 - val_accuracy: 0.6731\n",
            "Epoch 38/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0950 - accuracy: 0.6001 - val_loss: 0.8980 - val_accuracy: 0.6711\n",
            "Epoch 39/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0903 - accuracy: 0.6014 - val_loss: 0.8904 - val_accuracy: 0.6802\n",
            "Epoch 40/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0830 - accuracy: 0.6054 - val_loss: 0.9018 - val_accuracy: 0.6722\n",
            "Epoch 41/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0948 - accuracy: 0.6015 - val_loss: 0.9089 - val_accuracy: 0.6605\n",
            "Epoch 42/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0750 - accuracy: 0.6069 - val_loss: 0.9093 - val_accuracy: 0.6556\n",
            "Epoch 43/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0661 - accuracy: 0.6083 - val_loss: 0.9121 - val_accuracy: 0.6656\n",
            "Epoch 44/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0802 - accuracy: 0.6105 - val_loss: 0.8894 - val_accuracy: 0.6714\n",
            "Epoch 45/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0792 - accuracy: 0.6098 - val_loss: 0.9061 - val_accuracy: 0.6667\n",
            "Epoch 46/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0887 - accuracy: 0.6066 - val_loss: 0.9196 - val_accuracy: 0.6583\n",
            "Epoch 47/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.0659 - accuracy: 0.6094 - val_loss: 0.9059 - val_accuracy: 0.6612\n",
            "Epoch 48/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0890 - accuracy: 0.6090 - val_loss: 0.9157 - val_accuracy: 0.6634\n",
            "Epoch 49/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0789 - accuracy: 0.6049 - val_loss: 0.9079 - val_accuracy: 0.6664\n",
            "Epoch 50/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0653 - accuracy: 0.6154 - val_loss: 0.9218 - val_accuracy: 0.6666\n",
            "Epoch 51/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0738 - accuracy: 0.6127 - val_loss: 0.8927 - val_accuracy: 0.6703\n",
            "Epoch 52/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0622 - accuracy: 0.6129 - val_loss: 0.8909 - val_accuracy: 0.6717\n",
            "Epoch 53/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0703 - accuracy: 0.6078 - val_loss: 0.8998 - val_accuracy: 0.6766\n",
            "Epoch 54/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0769 - accuracy: 0.6097 - val_loss: 0.9592 - val_accuracy: 0.6500\n",
            "Epoch 55/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0807 - accuracy: 0.6072 - val_loss: 0.8810 - val_accuracy: 0.6734\n",
            "Epoch 56/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0564 - accuracy: 0.6134 - val_loss: 0.9094 - val_accuracy: 0.6789\n",
            "Epoch 57/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0554 - accuracy: 0.6184 - val_loss: 0.8568 - val_accuracy: 0.6789\n",
            "Epoch 58/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0389 - accuracy: 0.6228 - val_loss: 0.8940 - val_accuracy: 0.6778\n",
            "Epoch 59/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0657 - accuracy: 0.6161 - val_loss: 0.8931 - val_accuracy: 0.6731\n",
            "Epoch 60/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0615 - accuracy: 0.6125 - val_loss: 0.9096 - val_accuracy: 0.6684\n",
            "Epoch 61/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0478 - accuracy: 0.6209 - val_loss: 0.9081 - val_accuracy: 0.6584\n",
            "Epoch 62/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0652 - accuracy: 0.6141 - val_loss: 0.8650 - val_accuracy: 0.6883\n",
            "Epoch 63/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0549 - accuracy: 0.6109 - val_loss: 0.8864 - val_accuracy: 0.6792\n",
            "Epoch 64/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0527 - accuracy: 0.6189 - val_loss: 0.8914 - val_accuracy: 0.6706\n",
            "Epoch 65/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0490 - accuracy: 0.6195 - val_loss: 0.8731 - val_accuracy: 0.6787\n",
            "Epoch 66/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0544 - accuracy: 0.6144 - val_loss: 0.8783 - val_accuracy: 0.6683\n",
            "Epoch 67/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0653 - accuracy: 0.6112 - val_loss: 0.8885 - val_accuracy: 0.6852\n",
            "Epoch 68/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0207 - accuracy: 0.6273 - val_loss: 0.8720 - val_accuracy: 0.6878\n",
            "Epoch 69/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0490 - accuracy: 0.6141 - val_loss: 0.9102 - val_accuracy: 0.6755\n",
            "Epoch 70/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0486 - accuracy: 0.6162 - val_loss: 0.8675 - val_accuracy: 0.6787\n",
            "Epoch 71/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0504 - accuracy: 0.6169 - val_loss: 0.8644 - val_accuracy: 0.6812\n",
            "Epoch 72/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.0467 - accuracy: 0.6231 - val_loss: 0.8690 - val_accuracy: 0.6789\n",
            "Epoch 73/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.0361 - accuracy: 0.6243 - val_loss: 0.8681 - val_accuracy: 0.6816\n",
            "Epoch 74/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 1.0391 - accuracy: 0.6195 - val_loss: 0.8855 - val_accuracy: 0.6702\n",
            "Epoch 75/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0251 - accuracy: 0.6237 - val_loss: 0.8624 - val_accuracy: 0.6873\n",
            "Epoch 76/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0201 - accuracy: 0.6281 - val_loss: 0.8337 - val_accuracy: 0.6909\n",
            "Epoch 77/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0349 - accuracy: 0.6229 - val_loss: 0.8612 - val_accuracy: 0.6886\n",
            "Epoch 78/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0301 - accuracy: 0.6256 - val_loss: 0.8700 - val_accuracy: 0.6677\n",
            "Epoch 79/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0529 - accuracy: 0.6205 - val_loss: 0.8471 - val_accuracy: 0.6797\n",
            "Epoch 80/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0485 - accuracy: 0.6220 - val_loss: 0.8671 - val_accuracy: 0.6888\n",
            "Epoch 81/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0295 - accuracy: 0.6224 - val_loss: 0.8547 - val_accuracy: 0.6759\n",
            "Epoch 82/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0374 - accuracy: 0.6222 - val_loss: 0.8731 - val_accuracy: 0.6842\n",
            "Epoch 83/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0226 - accuracy: 0.6280 - val_loss: 0.8585 - val_accuracy: 0.6845\n",
            "Epoch 84/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0367 - accuracy: 0.6210 - val_loss: 0.8555 - val_accuracy: 0.6825\n",
            "Epoch 85/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0433 - accuracy: 0.6216 - val_loss: 0.8629 - val_accuracy: 0.6920\n",
            "Epoch 86/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0235 - accuracy: 0.6266 - val_loss: 0.8338 - val_accuracy: 0.6864\n",
            "Epoch 87/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0138 - accuracy: 0.6259 - val_loss: 0.8530 - val_accuracy: 0.6909\n",
            "Epoch 88/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0337 - accuracy: 0.6227 - val_loss: 0.8668 - val_accuracy: 0.6789\n",
            "Epoch 89/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0423 - accuracy: 0.6227 - val_loss: 0.8656 - val_accuracy: 0.6753\n",
            "Epoch 90/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0360 - accuracy: 0.6273 - val_loss: 0.8562 - val_accuracy: 0.6761\n",
            "Epoch 91/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0211 - accuracy: 0.6339 - val_loss: 0.8438 - val_accuracy: 0.6856\n",
            "Epoch 92/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0510 - accuracy: 0.6234 - val_loss: 0.8581 - val_accuracy: 0.6802\n",
            "Epoch 93/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0344 - accuracy: 0.6289 - val_loss: 0.8475 - val_accuracy: 0.6877\n",
            "Epoch 94/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0448 - accuracy: 0.6227 - val_loss: 0.8562 - val_accuracy: 0.6814\n",
            "Epoch 95/250\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 1.0273 - accuracy: 0.6268 - val_loss: 0.8559 - val_accuracy: 0.6872\n",
            "Epoch 96/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0111 - accuracy: 0.6335 - val_loss: 0.8521 - val_accuracy: 0.6756\n",
            "Epoch 97/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0338 - accuracy: 0.6288 - val_loss: 0.8966 - val_accuracy: 0.6742\n",
            "Epoch 98/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0283 - accuracy: 0.6313 - val_loss: 0.8425 - val_accuracy: 0.6942\n",
            "Epoch 99/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0177 - accuracy: 0.6341 - val_loss: 0.8476 - val_accuracy: 0.6831\n",
            "Epoch 100/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0033 - accuracy: 0.6377 - val_loss: 0.8763 - val_accuracy: 0.6858\n",
            "Epoch 101/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0212 - accuracy: 0.6305 - val_loss: 0.8298 - val_accuracy: 0.6909\n",
            "Epoch 102/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0041 - accuracy: 0.6338 - val_loss: 0.8186 - val_accuracy: 0.6938\n",
            "Epoch 103/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0116 - accuracy: 0.6322 - val_loss: 0.8170 - val_accuracy: 0.6891\n",
            "Epoch 104/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0251 - accuracy: 0.6262 - val_loss: 0.8378 - val_accuracy: 0.6827\n",
            "Epoch 105/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0080 - accuracy: 0.6359 - val_loss: 0.8318 - val_accuracy: 0.6897\n",
            "Epoch 106/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0318 - accuracy: 0.6282 - val_loss: 0.8398 - val_accuracy: 0.7063\n",
            "Epoch 107/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0077 - accuracy: 0.6398 - val_loss: 0.8536 - val_accuracy: 0.7025\n",
            "Epoch 108/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0039 - accuracy: 0.6387 - val_loss: 0.8225 - val_accuracy: 0.6967\n",
            "Epoch 109/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0205 - accuracy: 0.6310 - val_loss: 0.8632 - val_accuracy: 0.6853\n",
            "Epoch 110/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0193 - accuracy: 0.6321 - val_loss: 0.8546 - val_accuracy: 0.6764\n",
            "Epoch 111/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0055 - accuracy: 0.6374 - val_loss: 0.8575 - val_accuracy: 0.6964\n",
            "Epoch 112/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 1.0092 - accuracy: 0.6370 - val_loss: 0.8276 - val_accuracy: 0.7050\n",
            "Epoch 113/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0058 - accuracy: 0.6373 - val_loss: 0.8459 - val_accuracy: 0.6703\n",
            "Epoch 114/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0087 - accuracy: 0.6353 - val_loss: 0.8526 - val_accuracy: 0.6731\n",
            "Epoch 115/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0046 - accuracy: 0.6365 - val_loss: 0.8746 - val_accuracy: 0.6750\n",
            "Epoch 116/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0091 - accuracy: 0.6366 - val_loss: 0.8273 - val_accuracy: 0.6966\n",
            "Epoch 117/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0086 - accuracy: 0.6341 - val_loss: 0.8418 - val_accuracy: 0.7000\n",
            "Epoch 118/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0000 - accuracy: 0.6421 - val_loss: 0.8272 - val_accuracy: 0.6980\n",
            "Epoch 119/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9880 - accuracy: 0.6441 - val_loss: 0.8230 - val_accuracy: 0.6991\n",
            "Epoch 120/250\n",
            "100/100 [==============================] - 5s 45ms/step - loss: 0.9988 - accuracy: 0.6380 - val_loss: 0.8099 - val_accuracy: 0.6941\n",
            "Epoch 121/250\n",
            "100/100 [==============================] - 5s 45ms/step - loss: 1.0007 - accuracy: 0.6368 - val_loss: 0.8256 - val_accuracy: 0.6916\n",
            "Epoch 122/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 1.0054 - accuracy: 0.6338 - val_loss: 0.8336 - val_accuracy: 0.7013\n",
            "Epoch 123/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9720 - accuracy: 0.6448 - val_loss: 0.8172 - val_accuracy: 0.6883\n",
            "Epoch 124/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9910 - accuracy: 0.6388 - val_loss: 0.8225 - val_accuracy: 0.7022\n",
            "Epoch 125/250\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.9950 - accuracy: 0.6393 - val_loss: 0.8244 - val_accuracy: 0.7022\n",
            "Epoch 126/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9937 - accuracy: 0.6436 - val_loss: 0.7973 - val_accuracy: 0.7064\n",
            "Epoch 127/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9951 - accuracy: 0.6440 - val_loss: 0.8164 - val_accuracy: 0.7020\n",
            "Epoch 128/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9957 - accuracy: 0.6430 - val_loss: 0.8096 - val_accuracy: 0.7009\n",
            "Epoch 129/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9895 - accuracy: 0.6449 - val_loss: 0.7944 - val_accuracy: 0.7078\n",
            "Epoch 130/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9819 - accuracy: 0.6506 - val_loss: 0.8004 - val_accuracy: 0.7092\n",
            "Epoch 131/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9910 - accuracy: 0.6398 - val_loss: 0.8319 - val_accuracy: 0.6888\n",
            "Epoch 132/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9883 - accuracy: 0.6484 - val_loss: 0.8417 - val_accuracy: 0.6888\n",
            "Epoch 133/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9824 - accuracy: 0.6427 - val_loss: 0.8223 - val_accuracy: 0.6955\n",
            "Epoch 134/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9967 - accuracy: 0.6438 - val_loss: 0.8074 - val_accuracy: 0.6966\n",
            "Epoch 135/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9933 - accuracy: 0.6409 - val_loss: 0.7981 - val_accuracy: 0.7075\n",
            "Epoch 136/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9845 - accuracy: 0.6463 - val_loss: 0.8051 - val_accuracy: 0.7067\n",
            "Epoch 137/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9697 - accuracy: 0.6511 - val_loss: 0.8326 - val_accuracy: 0.6939\n",
            "Epoch 138/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9717 - accuracy: 0.6502 - val_loss: 0.8080 - val_accuracy: 0.7127\n",
            "Epoch 139/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9868 - accuracy: 0.6335 - val_loss: 0.7952 - val_accuracy: 0.7100\n",
            "Epoch 140/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9825 - accuracy: 0.6390 - val_loss: 0.8191 - val_accuracy: 0.6908\n",
            "Epoch 141/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9708 - accuracy: 0.6505 - val_loss: 0.8108 - val_accuracy: 0.7072\n",
            "Epoch 142/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9744 - accuracy: 0.6486 - val_loss: 0.7896 - val_accuracy: 0.7155\n",
            "Epoch 143/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9769 - accuracy: 0.6484 - val_loss: 0.8183 - val_accuracy: 0.6906\n",
            "Epoch 144/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9854 - accuracy: 0.6421 - val_loss: 0.8135 - val_accuracy: 0.7091\n",
            "Epoch 145/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9798 - accuracy: 0.6419 - val_loss: 0.8408 - val_accuracy: 0.6900\n",
            "Epoch 146/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9869 - accuracy: 0.6412 - val_loss: 0.7992 - val_accuracy: 0.7052\n",
            "Epoch 147/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9684 - accuracy: 0.6538 - val_loss: 0.7838 - val_accuracy: 0.7084\n",
            "Epoch 148/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9771 - accuracy: 0.6502 - val_loss: 0.8074 - val_accuracy: 0.6884\n",
            "Epoch 149/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9500 - accuracy: 0.6512 - val_loss: 0.7780 - val_accuracy: 0.7070\n",
            "Epoch 150/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9816 - accuracy: 0.6473 - val_loss: 0.8052 - val_accuracy: 0.7027\n",
            "Epoch 151/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9816 - accuracy: 0.6476 - val_loss: 0.7904 - val_accuracy: 0.7197\n",
            "Epoch 152/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9798 - accuracy: 0.6506 - val_loss: 0.8125 - val_accuracy: 0.6927\n",
            "Epoch 153/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9675 - accuracy: 0.6486 - val_loss: 0.8003 - val_accuracy: 0.7005\n",
            "Epoch 154/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9566 - accuracy: 0.6524 - val_loss: 0.8095 - val_accuracy: 0.7022\n",
            "Epoch 155/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9715 - accuracy: 0.6498 - val_loss: 0.8170 - val_accuracy: 0.7020\n",
            "Epoch 156/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9559 - accuracy: 0.6523 - val_loss: 0.8024 - val_accuracy: 0.7016\n",
            "Epoch 157/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9532 - accuracy: 0.6571 - val_loss: 0.7924 - val_accuracy: 0.7039\n",
            "Epoch 158/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9382 - accuracy: 0.6602 - val_loss: 0.8030 - val_accuracy: 0.6931\n",
            "Epoch 159/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9636 - accuracy: 0.6498 - val_loss: 0.8026 - val_accuracy: 0.7139\n",
            "Epoch 160/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9670 - accuracy: 0.6492 - val_loss: 0.7802 - val_accuracy: 0.7198\n",
            "Epoch 161/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9848 - accuracy: 0.6467 - val_loss: 0.8149 - val_accuracy: 0.6953\n",
            "Epoch 162/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9529 - accuracy: 0.6583 - val_loss: 0.8144 - val_accuracy: 0.7178\n",
            "Epoch 163/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9711 - accuracy: 0.6466 - val_loss: 0.8180 - val_accuracy: 0.7131\n",
            "Epoch 164/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9646 - accuracy: 0.6565 - val_loss: 0.7847 - val_accuracy: 0.7092\n",
            "Epoch 165/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9560 - accuracy: 0.6533 - val_loss: 0.7888 - val_accuracy: 0.7170\n",
            "Epoch 166/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9568 - accuracy: 0.6572 - val_loss: 0.7752 - val_accuracy: 0.7264\n",
            "Epoch 167/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9580 - accuracy: 0.6552 - val_loss: 0.7927 - val_accuracy: 0.7111\n",
            "Epoch 168/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9723 - accuracy: 0.6441 - val_loss: 0.7895 - val_accuracy: 0.7127\n",
            "Epoch 169/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9691 - accuracy: 0.6519 - val_loss: 0.7969 - val_accuracy: 0.7089\n",
            "Epoch 170/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9577 - accuracy: 0.6559 - val_loss: 0.7885 - val_accuracy: 0.7203\n",
            "Epoch 171/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9483 - accuracy: 0.6597 - val_loss: 0.7978 - val_accuracy: 0.7116\n",
            "Epoch 172/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9633 - accuracy: 0.6508 - val_loss: 0.8106 - val_accuracy: 0.7094\n",
            "Epoch 173/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9430 - accuracy: 0.6611 - val_loss: 0.7885 - val_accuracy: 0.6991\n",
            "Epoch 174/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9563 - accuracy: 0.6546 - val_loss: 0.7973 - val_accuracy: 0.6986\n",
            "Epoch 175/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9614 - accuracy: 0.6584 - val_loss: 0.7686 - val_accuracy: 0.7184\n",
            "Epoch 176/250\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.9521 - accuracy: 0.6637 - val_loss: 0.7859 - val_accuracy: 0.7202\n",
            "Epoch 177/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9502 - accuracy: 0.6542 - val_loss: 0.7769 - val_accuracy: 0.7075\n",
            "Epoch 178/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9538 - accuracy: 0.6538 - val_loss: 0.7811 - val_accuracy: 0.7181\n",
            "Epoch 179/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9589 - accuracy: 0.6559 - val_loss: 0.7907 - val_accuracy: 0.7134\n",
            "Epoch 180/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9401 - accuracy: 0.6634 - val_loss: 0.7652 - val_accuracy: 0.7219\n",
            "Epoch 181/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9524 - accuracy: 0.6587 - val_loss: 0.7851 - val_accuracy: 0.7109\n",
            "Epoch 182/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9588 - accuracy: 0.6493 - val_loss: 0.7721 - val_accuracy: 0.7206\n",
            "Epoch 183/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9551 - accuracy: 0.6539 - val_loss: 0.7651 - val_accuracy: 0.7280\n",
            "Epoch 184/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9512 - accuracy: 0.6561 - val_loss: 0.7952 - val_accuracy: 0.7100\n",
            "Epoch 185/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9565 - accuracy: 0.6552 - val_loss: 0.7972 - val_accuracy: 0.7000\n",
            "Epoch 186/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9646 - accuracy: 0.6460 - val_loss: 0.8004 - val_accuracy: 0.7111\n",
            "Epoch 187/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9512 - accuracy: 0.6554 - val_loss: 0.7644 - val_accuracy: 0.7142\n",
            "Epoch 188/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9595 - accuracy: 0.6557 - val_loss: 0.7830 - val_accuracy: 0.7141\n",
            "Epoch 189/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9465 - accuracy: 0.6592 - val_loss: 0.7834 - val_accuracy: 0.7194\n",
            "Epoch 190/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9404 - accuracy: 0.6612 - val_loss: 0.8023 - val_accuracy: 0.7022\n",
            "Epoch 191/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9432 - accuracy: 0.6580 - val_loss: 0.7642 - val_accuracy: 0.7192\n",
            "Epoch 192/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9582 - accuracy: 0.6567 - val_loss: 0.7574 - val_accuracy: 0.7234\n",
            "Epoch 193/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9525 - accuracy: 0.6531 - val_loss: 0.8030 - val_accuracy: 0.7006\n",
            "Epoch 194/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9561 - accuracy: 0.6575 - val_loss: 0.7777 - val_accuracy: 0.7148\n",
            "Epoch 195/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9467 - accuracy: 0.6601 - val_loss: 0.7823 - val_accuracy: 0.7308\n",
            "Epoch 196/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9518 - accuracy: 0.6523 - val_loss: 0.7812 - val_accuracy: 0.7084\n",
            "Epoch 197/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9460 - accuracy: 0.6634 - val_loss: 0.7604 - val_accuracy: 0.7333\n",
            "Epoch 198/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9494 - accuracy: 0.6612 - val_loss: 0.7858 - val_accuracy: 0.7189\n",
            "Epoch 199/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9494 - accuracy: 0.6574 - val_loss: 0.7981 - val_accuracy: 0.7042\n",
            "Epoch 200/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9391 - accuracy: 0.6597 - val_loss: 0.8006 - val_accuracy: 0.7056\n",
            "Epoch 201/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9578 - accuracy: 0.6467 - val_loss: 0.7620 - val_accuracy: 0.7353\n",
            "Epoch 202/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9270 - accuracy: 0.6672 - val_loss: 0.7731 - val_accuracy: 0.7161\n",
            "Epoch 203/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9420 - accuracy: 0.6630 - val_loss: 0.7753 - val_accuracy: 0.6988\n",
            "Epoch 204/250\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.9410 - accuracy: 0.6579 - val_loss: 0.7964 - val_accuracy: 0.6963\n",
            "Epoch 205/250\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.9465 - accuracy: 0.6576 - val_loss: 0.7428 - val_accuracy: 0.7289\n",
            "Epoch 206/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9414 - accuracy: 0.6591 - val_loss: 0.7691 - val_accuracy: 0.7280\n",
            "Epoch 207/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9462 - accuracy: 0.6586 - val_loss: 0.7707 - val_accuracy: 0.7308\n",
            "Epoch 208/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9484 - accuracy: 0.6581 - val_loss: 0.7676 - val_accuracy: 0.7239\n",
            "Epoch 209/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9287 - accuracy: 0.6653 - val_loss: 0.7727 - val_accuracy: 0.7209\n",
            "Epoch 210/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9491 - accuracy: 0.6605 - val_loss: 0.7877 - val_accuracy: 0.7136\n",
            "Epoch 211/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9437 - accuracy: 0.6663 - val_loss: 0.7789 - val_accuracy: 0.6955\n",
            "Epoch 212/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9066 - accuracy: 0.6768 - val_loss: 0.7619 - val_accuracy: 0.7236\n",
            "Epoch 213/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9338 - accuracy: 0.6659 - val_loss: 0.7764 - val_accuracy: 0.7017\n",
            "Epoch 214/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9280 - accuracy: 0.6637 - val_loss: 0.7559 - val_accuracy: 0.7287\n",
            "Epoch 215/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9234 - accuracy: 0.6698 - val_loss: 0.7655 - val_accuracy: 0.7245\n",
            "Epoch 216/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9243 - accuracy: 0.6663 - val_loss: 0.7862 - val_accuracy: 0.7047\n",
            "Epoch 217/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9303 - accuracy: 0.6613 - val_loss: 0.7665 - val_accuracy: 0.7358\n",
            "Epoch 218/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9351 - accuracy: 0.6640 - val_loss: 0.7500 - val_accuracy: 0.7194\n",
            "Epoch 219/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9253 - accuracy: 0.6617 - val_loss: 0.7657 - val_accuracy: 0.7180\n",
            "Epoch 220/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9298 - accuracy: 0.6687 - val_loss: 0.7744 - val_accuracy: 0.7211\n",
            "Epoch 221/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9321 - accuracy: 0.6652 - val_loss: 0.7658 - val_accuracy: 0.7119\n",
            "Epoch 222/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9368 - accuracy: 0.6604 - val_loss: 0.7513 - val_accuracy: 0.7277\n",
            "Epoch 223/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9203 - accuracy: 0.6682 - val_loss: 0.7945 - val_accuracy: 0.7117\n",
            "Epoch 224/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9319 - accuracy: 0.6700 - val_loss: 0.7549 - val_accuracy: 0.7109\n",
            "Epoch 225/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9320 - accuracy: 0.6648 - val_loss: 0.7766 - val_accuracy: 0.7114\n",
            "Epoch 226/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9486 - accuracy: 0.6559 - val_loss: 0.7688 - val_accuracy: 0.7247\n",
            "Epoch 227/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9287 - accuracy: 0.6623 - val_loss: 0.7607 - val_accuracy: 0.7123\n",
            "Epoch 228/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9354 - accuracy: 0.6615 - val_loss: 0.7610 - val_accuracy: 0.7122\n",
            "Epoch 229/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9608 - accuracy: 0.6541 - val_loss: 0.8248 - val_accuracy: 0.6928\n",
            "Epoch 230/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9226 - accuracy: 0.6677 - val_loss: 0.7847 - val_accuracy: 0.7156\n",
            "Epoch 231/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9167 - accuracy: 0.6706 - val_loss: 0.7447 - val_accuracy: 0.7250\n",
            "Epoch 232/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9295 - accuracy: 0.6698 - val_loss: 0.7587 - val_accuracy: 0.7189\n",
            "Epoch 233/250\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.9374 - accuracy: 0.6627 - val_loss: 0.7784 - val_accuracy: 0.7097\n",
            "Epoch 234/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9279 - accuracy: 0.6669 - val_loss: 0.7525 - val_accuracy: 0.7267\n",
            "Epoch 235/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9239 - accuracy: 0.6691 - val_loss: 0.7630 - val_accuracy: 0.7220\n",
            "Epoch 236/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9153 - accuracy: 0.6720 - val_loss: 0.7451 - val_accuracy: 0.7230\n",
            "Epoch 237/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9441 - accuracy: 0.6637 - val_loss: 0.7930 - val_accuracy: 0.7131\n",
            "Epoch 238/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9322 - accuracy: 0.6610 - val_loss: 0.7477 - val_accuracy: 0.7286\n",
            "Epoch 239/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9253 - accuracy: 0.6676 - val_loss: 0.7427 - val_accuracy: 0.7269\n",
            "Epoch 240/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9248 - accuracy: 0.6684 - val_loss: 0.7549 - val_accuracy: 0.7205\n",
            "Epoch 241/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9141 - accuracy: 0.6734 - val_loss: 0.7861 - val_accuracy: 0.7022\n",
            "Epoch 242/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9269 - accuracy: 0.6657 - val_loss: 0.7697 - val_accuracy: 0.7159\n",
            "Epoch 243/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9163 - accuracy: 0.6673 - val_loss: 0.7714 - val_accuracy: 0.7280\n",
            "Epoch 244/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9340 - accuracy: 0.6698 - val_loss: 0.7602 - val_accuracy: 0.7322\n",
            "Epoch 245/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9272 - accuracy: 0.6648 - val_loss: 0.7653 - val_accuracy: 0.7269\n",
            "Epoch 246/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9374 - accuracy: 0.6642 - val_loss: 0.7758 - val_accuracy: 0.7106\n",
            "Epoch 247/250\n",
            "100/100 [==============================] - 5s 48ms/step - loss: 0.9342 - accuracy: 0.6637 - val_loss: 0.7707 - val_accuracy: 0.7211\n",
            "Epoch 248/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9324 - accuracy: 0.6658 - val_loss: 0.7892 - val_accuracy: 0.6952\n",
            "Epoch 249/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9263 - accuracy: 0.6608 - val_loss: 0.7518 - val_accuracy: 0.7291\n",
            "Epoch 250/250\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.9206 - accuracy: 0.6703 - val_loss: 0.7619 - val_accuracy: 0.7153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL1ZoyRLtOf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecf19a86-7e2d-4232-e5d2-fc6551a9615c"
      },
      "source": [
        "loss_value,acc_value=model_DA.evaluate(test_gen,steps=50,verbose=0)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy  0.7221875190734863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmV0ZNmAlbV2",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of CNN after the Data Augmentation is 72%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prctXU4BswKK",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning / VGG16\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3g5IfA1gIkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x_tl, train_y_tl), (test_x_tl, test_y_tl) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDizVdoMKsLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjNdqZomEL9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_tl =tf.image.convert_image_dtype(train_x_tl, tf.float32)\n",
        "train_x_tl=train_x_tl/255\n",
        "\n",
        "test_x_tl =tf.image.convert_image_dtype(test_x_tl, tf.float32)\n",
        "test_x_tl = test_x_tl/255\n",
        "\n",
        "train_y_tl= to_categorical(train_y_tl)\n",
        "test_y_tl= to_categorical(test_y_tl)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa7uGKEtGsbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8812fc0-e0a5-4e32-9b4d-438e49795e3e"
      },
      "source": [
        "train_x_tl= tf.image.grayscale_to_rgb(tf.expand_dims(train_x_tl, axis=3))\n",
        "test_x_tl= tf.image.grayscale_to_rgb(tf.expand_dims(test_x_tl, axis=3))\n",
        "train_x_tl.shape, test_x_tl.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([60000, 28, 28, 3]), TensorShape([10000, 28, 28, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp25Yg2YK82H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE=32\n",
        "train_x_tl = tf.image.resize(train_x_tl, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "test_x_tl =tf.image.resize(test_x_tl, (IMAGE_SIZE, IMAGE_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TNEAouILHGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f97ee7db-e758-48f3-b858-0ad7e9f05634"
      },
      "source": [
        "train_x_tl.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 32, 32, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI5CN2fvERKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_tl = tf.data.Dataset.from_tensor_slices((train_x_tl, train_y_tl))\n",
        "train_dataset_tl = train_dataset_tl.shuffle(buffer_size=10000).batch(batch_size=128).repeat()\n",
        "test_dataset_tl = tf.data.Dataset.from_tensor_slices((test_x_tl, test_y_tl))\n",
        "test_dataset_tl = test_dataset_tl.shuffle(buffer_size=10000).batch(batch_size=128).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTpCPTP9ckLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "5e4651a0-25e7-402e-fce1-819bb82eb934"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False, \n",
        "                  input_shape=(32,32,3),\n",
        "                  classes=10)\n",
        "conv_base.trainable = False\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLhekzBUTKD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "229e5b19-6ab0-4b2e-fede-34744e5eb5fc"
      },
      "source": [
        "  from tensorflow.keras import models\n",
        "  from tensorflow.keras import layers\n",
        "  from tensorflow.keras import optimizers\n",
        "  \n",
        "  model_TL = Sequential()\n",
        "  model_TL.add(conv_base)\n",
        "  model_TL.add(layers.Flatten())\n",
        "  model_TL.add(layers.Dense(256, activation='relu'))\n",
        "  model_TL.add(layers.Dropout(0.7))\n",
        "  model_TL.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model_TL.compile(optimizer='Adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['acc'])\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "model_TL.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 14,848,586\n",
            "Trainable params: 133,898\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pK3P27HTRzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0de29ba9-68a4-4a7b-fc13-7a8d83c8834a"
      },
      "source": [
        "Epochs=50\n",
        "STEPS_PER_EPOCH=60000/128\n",
        "\n",
        "history=model_TL.fit(train_dataset_tl, epochs=Epochs,validation_data=test_dataset_tl,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3124 - acc: 0.1001 - val_loss: 2.3026 - val_acc: 0.1028\n",
            "Epoch 2/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1022\n",
            "Epoch 3/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0969 - val_loss: 2.3026 - val_acc: 0.1016\n",
            "Epoch 4/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3027 - val_acc: 0.0980\n",
            "Epoch 5/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0967 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "Epoch 6/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0952 - val_loss: 2.3026 - val_acc: 0.1002\n",
            "Epoch 7/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.0983\n",
            "Epoch 8/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0964 - val_loss: 2.3026 - val_acc: 0.1017\n",
            "Epoch 9/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0984 - val_loss: 2.3026 - val_acc: 0.0995\n",
            "Epoch 10/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3025 - val_acc: 0.0975\n",
            "Epoch 11/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.1002\n",
            "Epoch 12/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0971 - val_loss: 2.3026 - val_acc: 0.0936\n",
            "Epoch 13/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3026 - val_acc: 0.1002\n",
            "Epoch 14/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.0991\n",
            "Epoch 15/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0986 - val_loss: 2.3026 - val_acc: 0.0983\n",
            "Epoch 16/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0971 - val_loss: 2.3026 - val_acc: 0.1006\n",
            "Epoch 17/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1008\n",
            "Epoch 18/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0955 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 19/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0956 - val_loss: 2.3025 - val_acc: 0.1002\n",
            "Epoch 20/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0983 - val_loss: 2.3026 - val_acc: 0.1009\n",
            "Epoch 21/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.0998\n",
            "Epoch 22/50\n",
            "469/468 [==============================] - 7s 14ms/step - loss: 2.3027 - acc: 0.0968 - val_loss: 2.3026 - val_acc: 0.0983\n",
            "Epoch 23/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3026 - val_acc: 0.0995\n",
            "Epoch 24/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1039\n",
            "Epoch 25/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3027 - val_acc: 0.0986\n",
            "Epoch 26/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0975 - val_loss: 2.3025 - val_acc: 0.0983\n",
            "Epoch 27/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3026 - val_acc: 0.1020\n",
            "Epoch 28/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0979 - val_loss: 2.3026 - val_acc: 0.1016\n",
            "Epoch 29/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0970 - val_loss: 2.3027 - val_acc: 0.0980\n",
            "Epoch 30/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0982 - val_loss: 2.3026 - val_acc: 0.1072\n",
            "Epoch 31/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0974 - val_loss: 2.3026 - val_acc: 0.0977\n",
            "Epoch 32/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0960 - val_loss: 2.3026 - val_acc: 0.1013\n",
            "Epoch 33/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0975 - val_loss: 2.3026 - val_acc: 0.1005\n",
            "Epoch 34/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.0978\n",
            "Epoch 35/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3025 - val_acc: 0.1034\n",
            "Epoch 36/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.0997\n",
            "Epoch 37/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0988 - val_loss: 2.3025 - val_acc: 0.1003\n",
            "Epoch 38/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.0973\n",
            "Epoch 39/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1009\n",
            "Epoch 40/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1005\n",
            "Epoch 41/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0966 - val_loss: 2.3025 - val_acc: 0.1044\n",
            "Epoch 42/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3026 - val_acc: 0.0977\n",
            "Epoch 43/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0963 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 44/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0975 - val_loss: 2.3026 - val_acc: 0.0970\n",
            "Epoch 45/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0971 - val_loss: 2.3027 - val_acc: 0.1005\n",
            "Epoch 46/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0974 - val_loss: 2.3026 - val_acc: 0.1005\n",
            "Epoch 47/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0985 - val_loss: 2.3025 - val_acc: 0.0991\n",
            "Epoch 48/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3027 - val_acc: 0.0994\n",
            "Epoch 49/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0960 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 50/50\n",
            "469/468 [==============================] - 7s 15ms/step - loss: 2.3027 - acc: 0.0966 - val_loss: 2.3026 - val_acc: 0.1002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2l2qapNHYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f31ca070-4631-4839-ec58-e9bf4d29e51e"
      },
      "source": [
        "loss_value,acc_value=model_TL.evaluate(test_dataset_tl,steps=50,verbose=0)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy  0.09984374791383743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybgVDM3GlwDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FineTuning\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL2JiJSLl_3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model_TL_FT = Sequential()\n",
        "  model_TL_FT.add(conv_base)\n",
        "  model_TL_FT.add(layers.Flatten())\n",
        "  model_TL_FT.add(layers.Dense(256, activation='relu'))\n",
        "  model_TL_FT.add(layers.Dropout(0.5))\n",
        "  model_TL_FT.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model_TL_FT.compile(optimizer='Adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_-jkjGImgdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77467975-7cf3-4200-f036-5be3c987106d"
      },
      "source": [
        "Epochs=50\n",
        "STEPS_PER_EPOCH=50\n",
        "\n",
        "history=model_TL_FT.fit(train_dataset_tl, epochs=Epochs,validation_data=test_dataset_tl,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"vgg16_input_8:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"input_1:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"vgg16_input_8:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"input_1:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3296 - acc: 0.1011WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"vgg16_input_8:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 3) for input Tensor(\"input_1:0\", shape=(None, 48, 48, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3295 - acc: 0.1017 - val_loss: 0.3251 - val_acc: 0.1034\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0969 - val_loss: 0.3251 - val_acc: 0.1023\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1048 - val_loss: 0.3251 - val_acc: 0.1003\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0934 - val_loss: 0.3251 - val_acc: 0.1036\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0855 - val_loss: 0.3251 - val_acc: 0.1005\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1053 - val_loss: 0.3251 - val_acc: 0.0989\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0961 - val_loss: 0.3251 - val_acc: 0.1006\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0969 - val_loss: 0.3251 - val_acc: 0.1027\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1066 - val_loss: 0.3251 - val_acc: 0.1006\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0964 - val_loss: 0.3251 - val_acc: 0.1019\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0967 - val_loss: 0.3251 - val_acc: 0.0969\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1023 - val_loss: 0.3251 - val_acc: 0.1030\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0994 - val_loss: 0.3251 - val_acc: 0.1008\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1030 - val_loss: 0.3251 - val_acc: 0.1002\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0973 - val_loss: 0.3251 - val_acc: 0.0983\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1014 - val_loss: 0.3251 - val_acc: 0.0972\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0908 - val_loss: 0.3251 - val_acc: 0.0966\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0956 - val_loss: 0.3251 - val_acc: 0.1003\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0906 - val_loss: 0.3251 - val_acc: 0.0984\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1014 - val_loss: 0.3251 - val_acc: 0.1008\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0984 - val_loss: 0.3251 - val_acc: 0.1005\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0992 - val_loss: 0.3251 - val_acc: 0.1006\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.3251 - acc: 0.1047 - val_loss: 0.3251 - val_acc: 0.1009\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0981 - val_loss: 0.3251 - val_acc: 0.1011\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0959 - val_loss: 0.3251 - val_acc: 0.0972\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0953 - val_loss: 0.3251 - val_acc: 0.0973\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0970 - val_loss: 0.3251 - val_acc: 0.1011\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1020 - val_loss: 0.3251 - val_acc: 0.0967\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1024 - val_loss: 0.3251 - val_acc: 0.0992\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0966 - val_loss: 0.3251 - val_acc: 0.1006\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0989 - val_loss: 0.3251 - val_acc: 0.0966\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0991 - val_loss: 0.3251 - val_acc: 0.1025\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0916 - val_loss: 0.3251 - val_acc: 0.0992\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0952 - val_loss: 0.3251 - val_acc: 0.0977\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0986 - val_loss: 0.3251 - val_acc: 0.1023\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0966 - val_loss: 0.3251 - val_acc: 0.1030\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0933 - val_loss: 0.3251 - val_acc: 0.1003\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0959 - val_loss: 0.3251 - val_acc: 0.1002\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0944 - val_loss: 0.3251 - val_acc: 0.0983\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0950 - val_loss: 0.3251 - val_acc: 0.1003\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0961 - val_loss: 0.3251 - val_acc: 0.1017\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.1030 - val_loss: 0.3251 - val_acc: 0.1009\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1031 - val_loss: 0.3251 - val_acc: 0.1028\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0923 - val_loss: 0.3251 - val_acc: 0.1002\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1052 - val_loss: 0.3251 - val_acc: 0.1028\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0973 - val_loss: 0.3251 - val_acc: 0.1008\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3251 - acc: 0.0898 - val_loss: 0.3251 - val_acc: 0.1011\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0972 - val_loss: 0.3251 - val_acc: 0.0997\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.0972 - val_loss: 0.3251 - val_acc: 0.1011\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3251 - acc: 0.1022 - val_loss: 0.3251 - val_acc: 0.1008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AmliNugSQj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c1e0d2-cab7-428b-910d-b262ea685b64"
      },
      "source": [
        "loss_value,acc_value=model_TL_FT.evaluate(test_dataset_tl,steps=50,verbose=0)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy  0.09812500327825546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaHLKDLas_dF",
        "colab_type": "text"
      },
      "source": [
        "### Performance comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HviE30TQlqwz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        ">Configuration | Accuracy Score\n",
        ">--- | ---\n",
        ">DNN | 87.8\n",
        ">CNN | 89.8\n",
        ">Data Augmentation | 72.2\n",
        ">VGG16 | 9.9\n",
        ">VGG16 with Fine-tuning |9.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GP5PkD5mAMp",
        "colab_type": "text"
      },
      "source": [
        "CNN performed better than other models with accuracy of 89.8%. And CNN with Data Augmentation performed better than VGG16 with or without tuning. Data Augmentation is the best practice to improve generalisation properties and it reduces overfitting of the model in this problem.\n",
        "\n",
        "VGG makes use of lot of filters and aspects such as parameters brings complexity to VGG whihc might be the reason for low accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgoOE2W1pdfN",
        "colab_type": "text"
      },
      "source": [
        "###  CIFAR10 dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myC_8230sr1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ecf8515b-df09-450a-bb69-50c370549b9b"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "cifar10 = keras.datasets.cifar10\n",
        "\n",
        "(train_x_r, train_y_r), (test_x_r, test_y_r) = cifar10.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtNW1x7dtnxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y_r=to_categorical(train_y_r)\n",
        "test_y_r=to_categorical(test_y_r)\n",
        "\n",
        "train_x_r=train_x_r/255.0\n",
        "test_x_r=test_x_r/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7PbabSn4F3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b53ba2ed-1055-46e7-a113-2575c19f557e"
      },
      "source": [
        "print(train_x_r.shape,test_x_r.shape,train_y_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZC2_YmPuO9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  from tensorflow.keras import layers\n",
        "  model = Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                          input_shape=(32,32,3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  #model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1XCn_ZQxydR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3beb855-ad6d-4446-d942-edd35ade8f83"
      },
      "source": [
        "history=model.fit(train_x_r,train_y_r,epochs=100,validation_data=(test_x_r,test_y_r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5947 - accuracy: 0.4124 - val_loss: 1.2810 - val_accuracy: 0.5436\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2099 - accuracy: 0.5689 - val_loss: 1.0756 - val_accuracy: 0.6194\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0454 - accuracy: 0.6339 - val_loss: 1.0291 - val_accuracy: 0.6365\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9424 - accuracy: 0.6680 - val_loss: 0.9104 - val_accuracy: 0.6782\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8756 - accuracy: 0.6943 - val_loss: 0.9194 - val_accuracy: 0.6818\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8189 - accuracy: 0.7137 - val_loss: 0.8428 - val_accuracy: 0.7079\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7705 - accuracy: 0.7300 - val_loss: 0.8300 - val_accuracy: 0.7119\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7302 - accuracy: 0.7441 - val_loss: 0.7988 - val_accuracy: 0.7226\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6961 - accuracy: 0.7542 - val_loss: 0.7852 - val_accuracy: 0.7336\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6685 - accuracy: 0.7622 - val_loss: 0.7886 - val_accuracy: 0.7325\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6445 - accuracy: 0.7711 - val_loss: 0.7925 - val_accuracy: 0.7323\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6143 - accuracy: 0.7829 - val_loss: 0.7797 - val_accuracy: 0.7375\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5923 - accuracy: 0.7907 - val_loss: 0.7667 - val_accuracy: 0.7392\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5724 - accuracy: 0.7966 - val_loss: 0.7959 - val_accuracy: 0.7375\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5539 - accuracy: 0.8046 - val_loss: 0.7655 - val_accuracy: 0.7441\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5338 - accuracy: 0.8095 - val_loss: 0.7959 - val_accuracy: 0.7351\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5207 - accuracy: 0.8147 - val_loss: 0.7865 - val_accuracy: 0.7411\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5047 - accuracy: 0.8210 - val_loss: 0.7983 - val_accuracy: 0.7385\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4879 - accuracy: 0.8253 - val_loss: 0.7848 - val_accuracy: 0.7437\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4685 - accuracy: 0.8328 - val_loss: 0.8252 - val_accuracy: 0.7389\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4604 - accuracy: 0.8357 - val_loss: 0.8050 - val_accuracy: 0.7449\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4553 - accuracy: 0.8353 - val_loss: 0.8100 - val_accuracy: 0.7463\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4410 - accuracy: 0.8425 - val_loss: 0.8030 - val_accuracy: 0.7519\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4338 - accuracy: 0.8447 - val_loss: 0.8324 - val_accuracy: 0.7443\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4195 - accuracy: 0.8486 - val_loss: 0.8381 - val_accuracy: 0.7412\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4178 - accuracy: 0.8508 - val_loss: 0.8167 - val_accuracy: 0.7474\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4013 - accuracy: 0.8569 - val_loss: 0.8888 - val_accuracy: 0.7357\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3921 - accuracy: 0.8601 - val_loss: 0.9120 - val_accuracy: 0.7370\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3822 - accuracy: 0.8637 - val_loss: 0.8701 - val_accuracy: 0.7411\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3722 - accuracy: 0.8661 - val_loss: 0.9154 - val_accuracy: 0.7367\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3701 - accuracy: 0.8695 - val_loss: 0.8681 - val_accuracy: 0.7497\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3615 - accuracy: 0.8687 - val_loss: 0.8801 - val_accuracy: 0.7438\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3541 - accuracy: 0.8714 - val_loss: 0.9216 - val_accuracy: 0.7385\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3468 - accuracy: 0.8757 - val_loss: 0.9488 - val_accuracy: 0.7312\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3504 - accuracy: 0.8747 - val_loss: 0.9133 - val_accuracy: 0.7421\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3451 - accuracy: 0.8769 - val_loss: 0.9189 - val_accuracy: 0.7412\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3352 - accuracy: 0.8805 - val_loss: 0.9750 - val_accuracy: 0.7325\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3316 - accuracy: 0.8826 - val_loss: 0.9463 - val_accuracy: 0.7425\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3262 - accuracy: 0.8846 - val_loss: 0.9255 - val_accuracy: 0.7397\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3222 - accuracy: 0.8844 - val_loss: 0.9435 - val_accuracy: 0.7396\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3188 - accuracy: 0.8874 - val_loss: 0.9527 - val_accuracy: 0.7359\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3145 - accuracy: 0.8880 - val_loss: 1.0462 - val_accuracy: 0.7128\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3068 - accuracy: 0.8906 - val_loss: 0.9250 - val_accuracy: 0.7428\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3045 - accuracy: 0.8930 - val_loss: 0.9650 - val_accuracy: 0.7376\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3077 - accuracy: 0.8914 - val_loss: 1.0137 - val_accuracy: 0.7240\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2968 - accuracy: 0.8946 - val_loss: 0.9700 - val_accuracy: 0.7389\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2986 - accuracy: 0.8941 - val_loss: 0.9898 - val_accuracy: 0.7359\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2931 - accuracy: 0.8959 - val_loss: 0.9953 - val_accuracy: 0.7367\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2843 - accuracy: 0.8986 - val_loss: 1.0116 - val_accuracy: 0.7320\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2881 - accuracy: 0.8961 - val_loss: 1.0058 - val_accuracy: 0.7287\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2813 - accuracy: 0.9000 - val_loss: 1.0084 - val_accuracy: 0.7308\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2822 - accuracy: 0.8997 - val_loss: 1.0166 - val_accuracy: 0.7356\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2744 - accuracy: 0.9011 - val_loss: 1.0166 - val_accuracy: 0.7381\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2755 - accuracy: 0.9017 - val_loss: 1.0120 - val_accuracy: 0.7426\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2793 - accuracy: 0.9027 - val_loss: 1.0394 - val_accuracy: 0.7331\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2735 - accuracy: 0.9031 - val_loss: 1.0254 - val_accuracy: 0.7361\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2717 - accuracy: 0.9040 - val_loss: 1.0599 - val_accuracy: 0.7340\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2545 - accuracy: 0.9091 - val_loss: 1.0657 - val_accuracy: 0.7336\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2651 - accuracy: 0.9067 - val_loss: 1.0333 - val_accuracy: 0.7388\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2618 - accuracy: 0.9081 - val_loss: 1.0916 - val_accuracy: 0.7355\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2641 - accuracy: 0.9073 - val_loss: 1.0595 - val_accuracy: 0.7304\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2562 - accuracy: 0.9111 - val_loss: 1.0297 - val_accuracy: 0.7339\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2535 - accuracy: 0.9123 - val_loss: 1.0756 - val_accuracy: 0.7363\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2575 - accuracy: 0.9106 - val_loss: 1.0448 - val_accuracy: 0.7374\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2492 - accuracy: 0.9123 - val_loss: 1.0729 - val_accuracy: 0.7404\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2514 - accuracy: 0.9119 - val_loss: 1.0591 - val_accuracy: 0.7393\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2513 - accuracy: 0.9122 - val_loss: 1.0774 - val_accuracy: 0.7334\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2498 - accuracy: 0.9122 - val_loss: 1.0884 - val_accuracy: 0.7360\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2448 - accuracy: 0.9139 - val_loss: 1.0800 - val_accuracy: 0.7335\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2457 - accuracy: 0.9140 - val_loss: 1.0916 - val_accuracy: 0.7323\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2383 - accuracy: 0.9162 - val_loss: 1.1105 - val_accuracy: 0.7310\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2380 - accuracy: 0.9177 - val_loss: 1.1009 - val_accuracy: 0.7330\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2397 - accuracy: 0.9165 - val_loss: 1.1403 - val_accuracy: 0.7332\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2410 - accuracy: 0.9163 - val_loss: 1.0766 - val_accuracy: 0.7368\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2318 - accuracy: 0.9177 - val_loss: 1.1185 - val_accuracy: 0.7343\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2424 - accuracy: 0.9155 - val_loss: 1.1431 - val_accuracy: 0.7333\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2286 - accuracy: 0.9218 - val_loss: 1.0725 - val_accuracy: 0.7347\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2336 - accuracy: 0.9181 - val_loss: 1.1407 - val_accuracy: 0.7255\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2312 - accuracy: 0.9189 - val_loss: 1.1274 - val_accuracy: 0.7278\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2281 - accuracy: 0.9202 - val_loss: 1.1661 - val_accuracy: 0.7274\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2322 - accuracy: 0.9197 - val_loss: 1.1235 - val_accuracy: 0.7298\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2259 - accuracy: 0.9223 - val_loss: 1.1088 - val_accuracy: 0.7321\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2195 - accuracy: 0.9229 - val_loss: 1.1491 - val_accuracy: 0.7287\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2263 - accuracy: 0.9229 - val_loss: 1.1279 - val_accuracy: 0.7317\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2206 - accuracy: 0.9234 - val_loss: 1.1680 - val_accuracy: 0.7319\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2236 - accuracy: 0.9223 - val_loss: 1.1400 - val_accuracy: 0.7336\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2224 - accuracy: 0.9224 - val_loss: 1.1781 - val_accuracy: 0.7296\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2238 - accuracy: 0.9232 - val_loss: 1.1174 - val_accuracy: 0.7323\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2221 - accuracy: 0.9234 - val_loss: 1.1537 - val_accuracy: 0.7382\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2170 - accuracy: 0.9231 - val_loss: 1.1389 - val_accuracy: 0.7315\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2246 - accuracy: 0.9245 - val_loss: 1.1866 - val_accuracy: 0.7267\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2178 - accuracy: 0.9240 - val_loss: 1.1768 - val_accuracy: 0.7310\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2205 - accuracy: 0.9230 - val_loss: 1.1811 - val_accuracy: 0.7318\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2104 - accuracy: 0.9264 - val_loss: 1.2051 - val_accuracy: 0.7290\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2224 - accuracy: 0.9228 - val_loss: 1.1330 - val_accuracy: 0.7328\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2111 - accuracy: 0.9276 - val_loss: 1.1717 - val_accuracy: 0.7309\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2123 - accuracy: 0.9265 - val_loss: 1.1809 - val_accuracy: 0.7225\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2061 - accuracy: 0.9296 - val_loss: 1.1940 - val_accuracy: 0.7316\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2138 - accuracy: 0.9277 - val_loss: 1.1774 - val_accuracy: 0.7307\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2079 - accuracy: 0.9281 - val_loss: 1.2254 - val_accuracy: 0.7258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiJYkeo45BzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c98cacc8-e5ba-40d5-ab0c-ef95d461b7d7"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU5dn48e+dfSchCVsCJOy7KIgLtuLWIopLrVu1rVqlb6vVWn1b7aa1/b3dF21daq3WXRE3tC4Vi+IGEhCQfYckBAgh+zqZuX9/PBMYQsBBmEzIuT/XNRczc5a5z0x47vMs5zmiqhhjjPGumGgHYIwxJrosERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQLjKSLyLxH5VZjrbhaRMyMdkzHRZonAGGM8zhKBMUchEYmLdgym+7BEYLqcYJPM/4rIMhGpF5F/ikhvEXldRGpFZI6IZIWsf56IrBCRKhF5R0RGhiw7VkQWB7d7Fkhq91nnisiS4LYfisi4MGM8R0Q+EZEaESkWkTvbLT8luL+q4PKrgu8ni8gfRWSLiFSLyPvB96aISEkH38OZwed3isgsEXlCRGqAq0Rkkoh8FPyMMhH5m4gkhGw/WkTeEpHdIrJDRH4sIn1EpEFEskPWO05EykUkPpxjN92PJQLTVV0EnAUMA6YDrwM/BnJxf7c3AojIMOBp4PvBZa8Br4hIQrBQfAl4HOgJPBfcL8FtjwUeBr4NZAN/B2aLSGIY8dUD3wAygXOA74jIBcH9DgzG+9dgTOOBJcHt/gBMAE4OxvRDIBDmd3I+MCv4mU8CfuBmIAc4CTgD+G4whnRgDvAG0A8YArytqtuBd4BLQvb7deAZVfWFGYfpZiwRmK7qr6q6Q1VLgfeABar6iao2AS8CxwbXuxT4t6q+FSzI/gAk4wraE4F44C+q6lPVWcDCkM+YAfxdVReoql9VHwWag9sdlKq+o6qfqmpAVZfhktGpwcVfA+ao6tPBz61Q1SUiEgNcA9ykqqXBz/xQVZvD/E4+UtWXgp/ZqKqLVHW+qraq6mZcImuL4Vxgu6r+UVWbVLVWVRcElz0KXAkgIrHA5bhkaTzKEoHpqnaEPG/s4HVa8Hk/YEvbAlUNAMVAXnBZqe47s+KWkOcDgVuCTStVIlIF9A9ud1AicoKIzA02qVQD/4M7Mye4jw0dbJaDa5rqaFk4itvFMExEXhWR7cHmov8LIwaAl4FRIlKIq3VVq+rHnzMm0w1YIjBHu224Ah0AERFcIVgKlAF5wffaDAh5Xgz8P1XNDHmkqOrTYXzuU8BsoL+q9gAeANo+pxgY3ME2u4CmAyyrB1JCjiMW16wUqv1UwfcDq4GhqpqBazoLjWFQR4EHa1UzcbWCr2O1Ac+zRGCOdjOBc0TkjGBn5y245p0PgY+AVuBGEYkXka8Ak0K2/QfwP8GzexGR1GAncHoYn5sO7FbVJhGZhGsOavMkcKaIXCIicSKSLSLjg7WVh4E/iUg/EYkVkZOCfRJrgaTg58cDPwU+q68iHagB6kRkBPCdkGWvAn1F5Psikigi6SJyQsjyx4CrgPOwROB5lgjMUU1V1+DObP+KO+OeDkxX1RZVbQG+givwduP6E14I2bYIuA74G1AJrA+uG47vAneJSC3wc1xCatvvVmAaLintxnUUHxNcfCvwKa6vYjfwWyBGVauD+3wIV5upB/YZRdSBW3EJqBaX1J4NiaEW1+wzHdgOrANOC1n+Aa6TerGqhjaXGQ8SuzGNMd4kIv8FnlLVh6Idi4kuSwTGeJCIHA+8hevjqI12PCa6rGnIGI8RkUdx1xh835KAAasRGGOM51mNwBhjPO6om7gqJydHCwoKoh2GMcYcVRYtWrRLVdtfmwIchYmgoKCAoqKiaIdhjDFHFRE54DBhaxoyxhiPs0RgjDEeZ4nAGGM8zhKBMcZ4nCUCY4zxOEsExhjjcZYIjDHG44666wiMMaa7WlVWw3vryhmUk8ZxA7PomZrQKZ9ricAYYyJkZ20TO2uaGd0vg7Yb5QUCynOLinl1WRm56YkM7JlKYnwMryzdxoptNftsP6BnCjECdc1+6ptbuWP6KC6bNKCjjzoslgiMMZ7Q0hqgqqGFuuZWemckkZrYcfGnqtS3+GlobqXFH8DnV+JihOSEWFISYtlZ08zq7TWs3l5LQ4ufHsnxZCTHk5uWQF5mCnlZyWyuqOfRDzfz2qdl+PzK6H4ZXPuFQgb0TOWuV1eytLiKwpxU1u2o44WaUgDG5vXgF+eN5suj+7B1dwNFW3azorSG2BghNTGO9KQ4hvUJ5+Z5h84SgTGmy3hl6Tb8AeWccX2Jjw2vC1NVWb29ljdXbKdocyUV9S1U1rdQ2+RDcTdx9qvS5Avss12v9EQG9EwhPjYGvyr+gLK7voUdNU00tPg/83NFICE2hubWQIfL0xPjuPLEgQzKSeXRj7Zw87NLAchJS+RPlxzDhcfmISI0+fzUNProlZG0Z9s+PZKYVNgzrOM/Eo66aagnTpyoNteQMd1Lk8/PHS+v4NmiYgD69kjimsmFnDQ4m4r6Fsprm9m6u4H1O2tZt6OOyoYW0pPiyUiKo7LBx9bdDYjAmH496J2RRFaKO0uX4P5FoEdyPD1SEkhNiKWsuonNu+oprmzAH1BiRIiNEXqmJtA7I4le6YmkJcURHxtDfKzQ6lcafX4aWvxkpcQzsm8GQ3ulk5wQS5PPT3Wjj/LaZkoqGymtaiQlIZbpx/QjLVjrCASUd9eVs7G8nosn5pORFN/p37GILFLViR0us0RgjPm8VJV1O+v4cP0uVpXVsmp7DZvK68lJT6QgO4WB2alkJMeTGOcK1K27G1izvZa1O+rol5nMqcNyOb4gi7vfXseykmpuOG0IEwZm8fd5G5i/cfc+nxUjMDA7lSG90shJS6SuuZWaRh/xscLpI3pz1qje5KYnRumb6PosERhjPrdAQNlcUc/Skio27KzH5w/gDyiVDT4+WL+L7TVNAGSnJjCybwaFOalU1DezeVcDW3c3UNfcumdf6YlxjOibzpBe6WzaVUfR5kpaA0paYhx/uuQYvjS6z551l5dWU7y7gV4ZieSmJdErI5Gk+NhOP/7u4mCJwPoIjOlmfP4Ab67YzpKtVWwor2PjrnpSE+IYPyCT8fmZBFRZWlLFkuJqqhpaSEmIJTUxjrgYobk1QHNrAJ8/QEAVVahu9FHb5ArzGIH42BhiY4SUhFgmFfbki0NzOWVoDnmZyXtGxoRSVZpbA7T4A6Qnxu2zTl1zK0WbdzOkVxr5WSn7bDcmrwdj8npE9ssygNUIjOnyVpXV8MT8LQztlcZpI3oxMDsVVWVbdRMby+tIjo+ld0YS6UlxvPRJKf94bxOlVY0kxsUwKDeNQbmp1DT6WFJctadAz0iK45j+mfTJSKKhxU9dcyutgQBJcbEkxscQHxtDjAgCpCTGMjavB8f0z2RIbhpxYXbimq4lajUCEZkK3A3EAg+p6m/aLR8IPAzkAruBK1W1JJIxGXO0aPL5ufvtdfxj3kZiRGjxB7jzlZXkZSZT3ejbp8kl1PEFWdx1/mhOG96LmJi9Z9+BgLKpoh4BCnNSOzx7N94UsUQgIrHAvcBZQAmwUERmq+rKkNX+ADymqo+KyOnAr4GvRyomY7qS5lY/ZVVN7Khpoq65lfoWN/pkR3UT26ob+XjTbkoqG7l4Qj4/njaS6kYf76zZycebd5OblsjQ3ukMzk2judXPzppmdtU3c3xBT44v6HjYYUyMMDg3rZOP0hwNIlkjmASsV9WNACLyDHA+EJoIRgE/CD6fC7wUwXiMibjqBh+lVY0kJ8SSFB9DdaOP1WW1rCqrobiygaoGH9WNPnbVNbOztpmOWmZjY4Te6YkMyE7hd18dx8mDcwDISk3gqpxCrppc2MlHZbq7SCaCPKA45HUJcEK7dZYCX8E1H10IpItItqpWRDAuYz43f0BZsKmC/6zYQVpiHGeN6s3YvB7sqG3iH/M28fTHW2n07X8xUkJsDP17JpOZ4sapj+ybQX5WMvlZKfTJSCItKY60xFjSk+LJSUskNsaabUznifaooVuBv4nIVcA8oBTY73+RiMwAZgAMGHDk59kwJtSuumYAMpLiiY8VtlQ0sGhLJUVbKnlr5Q521TWTFB9DS2uAv81dT6/0RKoafPhVOX98P84c2ZuW1gCNPj8pCbF7hlSGe6WsMZ0tkomgFOgf8jo/+N4eqroNVyNARNKAi1S1qv2OVPVB4EFwo4YiFbDxhuZWPws27mZpcRUDc1IZm9eDvj2S+M/KHTy9YCsfbdxbIY2PFXx+9yeXnhjHKUNzOHdcP04f0Ysmn5//rt7Jf9fsJCc1gWu/MIj+PVMO9LHGdFmRTAQLgaEiUohLAJcBXwtdQURygN2qGgBux40gMuaIq270MWflDt5csZ331+/aby6ZGIGAQn5WMjefOYys1HhqGn3UNrcysGcqEwZmMaRX2j5NNskJsVw0IZ+LJuR39uEYc0RFLBGoaquI3AC8iRs++rCqrhCRu4AiVZ0NTAF+LSKKaxq6PlLxGO/YUF7H/I0V7K5robLBx4byOj7csAufX+nXI4mLjsvn9BG9mFiQRfHuRj4trWJjeT2Th+RwypCcfYZcGuMFdkGZOSoFAsrKshpKqxqJjxXiY2PYvKueWYtLWVq8t3UxJSGWPj2SOHNkb6aN7csx+T1s/LzxJJtiwhz1AgFlzY5aPtpQwfyNFSzYtJvqRt9+643ok85PzxnJl0f3oVdGIolxNjeNMZ/FEoHp0lZuq+GRDzbx9uqd7K5vAaB/z2S+PLo3Jw3OZmivdPwBxecP0CM5nqG9I3PjDmO6M0sEpsupbXKzWj4xfyvvr99FcnwsZ4/pw0mDszlpcPZ+k5MZYw6PJQITFYGA8tKSUu57ZwOBgJLfM4W8zGQ27Kxj8VY3NXHvjER+OHU4V0waSI+Uzr+RhzFeYYnAdCp/QHl37U5+/+ZaVpXVMCYvgwE9U9zonZIq+mUmc90XB/HFoblMGJhFQpxdhGVMpFkiMBGxvLSaN1dsJyUhjl7piaQmxvHeunLeXLGdXXUtDOiZwj2XH8u5Y/vacE1joswSgTliGlv8vLVqB499uJmiLZWIsM+kasnxsZw+shfTxvTlrFG97WzfmC7CEoE5LLVNPv69rIw5q3bw3rpdNLcGKMhO4WfnjuKrE/KJjxV21jSzu6GFkX0ySE6w4ZzGdDWWCMznUry7gX99uJlnFxZT19xKXmYyl08awJdG9ebEQdn7NPcU5MRRQGoUozXGHIwlAhM2f0B5Z81Onv64mP+u3kGMCOeO68vVkwsZZ1fsGnPUskRgwjJrUQl//M8ayqqbyElL5H9OHczXTxpI3x7J0Q7NGHOYLBGYg2ps8fOzl5cza1EJEwZmccf00ZwxspfNrW9MN2KJwHSoudVP0eZKfvnqStbsqOXG04dw05nD7M5ZxnRDlgjMHq3+AK8s28bsJduYv3E3jT4/PVMT+NfVkzh1WG60wzPGRIglAkNzq5/nF5Vy/7vrKd7dyICeKVw8MZ8vDM3lpMHZpCXan4kx3Zn9D/eobVWN7m5d63Yxf2MF9S1+xvfP5M7pozl9RC8bAWSMh1gi8KCPNlQw47EiaptbKchO4cLj8pg2pi8nDc62BGCMB1ki8JhXl23jB88uZWB2Ci9eOYEhvdKiHZIxJsosEXRTqsrirVX8e1kZDS2tpCTE0dzq56mPtzJxYBb/+MZEMlMSoh2mMaYLsETQzfgDyj/e28gzH29lc0UDiXExZCTH09DcSoPPz7SxffnjxceQFG9z/hhjHEsE3UhLa4Cbn13Cvz8t44TCnnz3tCGcPaYP6Unupi6qan0Axpj9WCLoJhpaWvn244t4b90ufjJtJNd9cdB+61gSMMZ0xBJBN7B2Ry0/nLWMZSVV/O6r47hkYv9oh2SMOYpYIjiKlVU38ue31jJrUQmpiXHcd8UEpo7pE+2wjDFHGUsER6mZC4v5+ezlBAJw9eRCbjhtCFmpNgrIGHPoLBEcZZp8fu54eQXPFhVz8uBsfnvROPr3TIl2WMaYo5glgqPI+p113PTMJ6zYVsP1pw3mB2cNt9lAjTGHzRLBUaDVH+Dv8zZy99vrSEmI5aFvTOTMUb2jHZYxppuwRNDFfVpSze0vLmN5aQ3TxvbhF+eNITc9MdphGWO6EUsEXVRVQwt/+M8anlywlezURO6/4jjOHts32mEZY7qhiCYCEZkK3A3EAg+p6m/aLR8APApkBte5TVVfi2RMR4P31+3ixmc+oaqhhatOLuDms4aREbw62BhjjrSIJQIRiQXuBc4CSoCFIjJbVVeGrPZTYKaq3i8io4DXgIJIxXQ0mLe2nOseK6IgO5UnvnUCo/plRDskY0w3F8kawSRgvapuBBCRZ4DzgdBEoEBbSdcD2BbBeLq8tiQwKDeNJ689gZ52XYAxphPERHDfeUBxyOuS4Huh7gSuFJESXG3gex3tSERmiEiRiBSVl5dHItaoe2N5mSUBY0xURDIRhONy4F+qmg9MAx4Xkf1iUtUHVXWiqk7Mze1eN1Fv8vn52UvL+Z8nFjOiT7olAWNMp4tk01ApEDr7WX7wvVDfAqYCqOpHIpIE5AA7IxhXl7GxvI7vPrmY1dtrufaUQn44dQQJcdHOzcYYr4lkIlgIDBWRQlwCuAz4Wrt1tgJnAP8SkZFAEtA9237aWb29hisfWoA/oDxy1fGcNqJXtEMyxnhUxBKBqraKyA3Am7ihoQ+r6goRuQsoUtXZwC3AP0TkZlzH8VWqqpGKqatYXlrNlf9cQFJcLM9++wQG59p9g40x0RPR6wiC1wS81u69n4c8XwlMjmQMXc3S4iq+/s8FpCfF8/R1JzIg2yaMM8ZEl11Z3Ilqmnx898nFZCTH88yME8nPsiRgjIk+SwSd6FevrqSsupEXvjvZkoAxpsuwISqdZM7KHcwsKuE7UwYzvn9mtMMxxpg9LBF0gsr6Fm574VNG9EnnxjOGRjscY4zZhzUNRZg/oPzvrGVUN7bw2DWTSIyLjXZIxhizD6sRRJCq8tOXljNn1Q5+Mm2kTSBnjOmSLBFE0J/nrOPpj7fynSmDuWpyYbTDMcaYDlkiiJDHPtrMPW+v45KJ+fzwy8OjHY4xxhyQJYIIeGrBVn7+8grOHNmL/7twLCJ2g3ljTNdlieAIe2rBVn784qecNjyXv33tOOJi7Ss2xnRtVkodQc98vDcJ3H/lBJLibYSQMabrs0RwhHywfhc/eWk5pw47CpJAwA8LH4I1r0c7EmNMF2CJ4Ago3t3ADU8tZlBOKvdecVzXTgKVm+Ff58C/b4GnL4eiRyLzOTVlMOsa2PJhZPZvjDliLBEcpsYWPzMeX4Q/oPzjGxNJS+yC1+g1VsGWj+D9v8D9p8COFXDe32Dol+DV78OHf91/m9ZmePMnMPMb4G899M98/Yew/HmXdN79nauFGGO6pC5Yah1dbn9hGau31/DIVcdTkJN6ZHZattQ125xyM8Qlfvb6viZYPgsGTYEe+SH7WQYvfQd2LN/73sBT4ML7IXMAjLsUXpwB//kp7FoLJ3wHeo+CqmJ47ptQusht0+uPMOVH4ce/9k1YNRu+cIvb19z/B5vmwYUP7BtfNLQ2h/edRpoq2Ggy00VYIjgM760r56Ul2/j+mUOZMvwI3WFs+fPw0vXQ2gjlq+GihyEmWHFrqoZVr0DfY6D3GFeQbPkQZn8PKtZDfAp88VY46Qb45HF448eQ0hPOvBN6jYZeI11B3FYAxSXARf+EtD6uz2DxY9DvONd85PfBJY/Bqldh3u9g6FmQd9z+8e7eCMUfw4hzIDEdWhrg37dCznA49TaIjYfBp7n37j0RvvRLmHDV/oVgazO89F2o3AQZee4x7pJ9PzPgdzWUsqUw6nwY+1XoOz78AnX92/DkV2HSt+H0n0JiFG4IVLY0mHjXwzWvQ1ZB58fQprES6isgs3/XSI4mauRouyHYxIkTtaioKNph0OoPcM4979Pga2XOD04Nfw6hgB+2f+rOtksXQ1OVK8zyjnOF+nt/gP4nQuEXYN7v3Vn61F/DtsXw3NVQtcXtp+cg6DUKVr/qzu7PuANWvOheJ2e5/+RDzoQL/w6pOZ8dV30FLHsWljwF8clwwf2QM8Tt576TXSH/7XfdMoDKLS6+JU+B+iElB6bc5uL78K9w1WtQEHLPocrNLmFtmgeFX3RxZfTbu/yN22H+fa7GUr/T1SRiYuGbsyFvgltnzi/g/T9B/xPc9xdohcQMiIlzj4x+cMK3YcxXXZJr75Wb4JMn3HY9BsD0v8CQM9r9sC3w7m8gZxiMnA4JR6iWV74W3v8zLH3aJedAK6T3hW/9B5J6hL+f2h0uYfc9xsUec4j9Ua0tsOFt97uteR0CPkDcCULBKfDl/3Pxmb1KioInJ32jHclhEZFFqjqxw2WWCD6fJxds4ScvLue+K45j2tgw/0BKFsHsG2DnSvc6JdsV2hXr965z7NfhnD9CbIIrHBfc7wqkNW9Aeh849y9QXexqBiUL4dgr3dltW4G1fg6881t3hn7yjXtrE4djw3/h8Qth2Nku3l1rXLOTCEy8xvU1vPdH2PKBW3/8lXDBvfvvRxUWPQL/+RkkZcLXX4Dc4a5Aevoyd6Y+7Xdu3ZoyePjL0FwL17zh+jVmXQ0TrnYFeMNu1/y0Y6VLRAG/q5nsXAHp/eDUH8LEq/f9/LuPccnz5BuDtah1cMUsV9tp8/E/4LVb3fOENBh5HiRlQG0Z1O9yzW8nf29vQjyY8rWw5ElY/W/3WbEJcOJ3XJNZ2VL3nRZ+Eb72nPsuN8yFko9draxgsku+od/dkqfgzR+7kwdwJwATrobjr3Uxtuf3wdb5sO5N2L7c1baqit33lZoLYy+BPmNckq7YACtfhrTecNFDMPAk8DW6WlTlJhh8uvvuPk9zlt/nTlI+ecIlnOHT3P4SOrgnR1dqMmtthrfucP8HU3Lg0ifc93KUskRwhNU0+Tjt9+8wODeNZ7994t4rh5fNdIV8ViH0LHR/PHGJIDGu6WX+fa4Z5vSfuLOvzIHuj76pGrZ94gqzwafv/Y8QCMDz17j/RMOnwfn3Ru9s7fUfwYIHXPy5w1wt5oT/gR55brmq6xtY/QqceRekZh94X2VL4YmvurPR6Xe7M/Ue+fCtORCftHe9ig3w8FR31ttUDX3GwTdf6fhsvy2G9W/Du791Ber3FkP2YLds9ya4Zzyc/TtXa/A1wd+/4M7Mvzvf/U7NtXDPsa5Z67TbYcnTsPIlQFwSTkiFsiWuNvHlX7kk0VGh1VTjYljwgHtdcAqMONc9Qs8qFz/mElLBF9zJQG3Z3mUSC33HuQI7Ic0t2/oRDDjJnSiUr4aFD8OW913NYtofYOS5btuSRfDxg7D2dfe9xSZA79GuFplVCPkTXW0xNn7fuLd9srfWOWgKbF0Avvq9yzMHwrAvuybG7CHukd5373eg6pJK6SL3Xfp90LDLJYCaUtcM1lAJzdUQl+z2k9kfevR3yW3nKihf4z774n/tH9+REvC7zyktcv8Om+pq4KEqNsBzV8H2ZS7ZbprnTsCm3w3jv/b5PrcxeIx9xuyb5DuJJYIj7Nevr+LBeRuZff0pjM0PVutXvwbPXA4IcIDvdOI1rr3+UJoC/D7XhNR/UnTPlFShpf7Itavv3ujOiCs3Q3wqfHuea4pqb/tyeGSaO3uc8S6k9/7sfVeXwp9Hw5Tb93ZyFz3iRkhdv9AlMthb0znj5+4sfe6vXbPQtf+F/GBzVPsz1E3vuaS4cwX0OxYmfgvGXORqCOWr3T4/uAfqtrva3Rl3QFrugWOdc6dbf+iXXAEzaIorkDe965okmqqhpc4VXidd7z4vtJZXssgl0h2fugKtocLVFBPSXT/K8Kkw6LTwf7emGnd8W96HwWfAqPNcYlz/lqvZbHrP9V+1ScyAnKEuIWxbAjUl+++z8Iuu32rIWa42suUDV8PdtQaqtrpaSmK6G6iQ1hs+fc7VKs//22f/zbe2uAS5/i1YN8cV1mMvhknXuRpM2VJXk1r3H/A1uLN8XwP4W9z2EgMagIGT3eCM2jJ34rXxXVfLOv8+GDHN1UCfu8r9LhOvcX8zyVluH36f65PbNM813dWWuZOGURfAmK+4RD7/Xpe4W2pdku8z1p30Tblt3/6ZsmXu+4+NdydHmQNcrf8IDLKwRHAElVU3curv3mH6Mf344yXHuDerS+GBye7M5po3ob7cVacbq9wfnL8FckfuLVyMU7cT/v0DGHfZ3rPZjlRthZj4Q2ujfWSa+x2u/9gVJjO/4QrWm1fsW7g8e6WrRVz9GjxyDgw903WSH4y/1f3HX/CAK/yTekBcEtTtcMvzJriaR36H/+f252vatyZ0qPw++OheeOfXrkA+8TsuqUTirDMQcGf3Fevdo3yNK9CrS1yNreAUGHCiqw3HJrhC7rOSUPtkO/f/XI1qyo9dIvf7oHiBSxgJqW5/tTtg7Rsu8TbXuL+PgSe7RLJqNrQ2uXb9mlKITXQ1oLRcF1N8shs8kTfB9St98rjrv2mrkWUVwugLXTIJ7cfy+1zinn8fJAcHYSSkwNu/dP/fMwe42mJ6b9e0uTV4DU1MnEs2oy90yXn7p24495b3XU3/ksdcwV+1FR46y62bNdCVK3XbXe1pym3udz2MWpIlgiPojpeX8+SCrcy9dQr9e6a4M7VHp7uzoQOd1ZrOt/CfLsl8+z3XLPK7Qa7f5IL79l2vcgvcO8mdpbU2ucQR7m+o6jr4Fz/mmpgGnerOfqM1Esjvc8dxJPqFoknVDXte+rSrIZUscmfS7aX1dk1Vw6a6770t8TXsdoX7lo9c/8+Yr+w9ez8QX5NrSssqdB3xB6uJlC1z/UjFC9zr3mNczW/oWftuV10Cy19wgx8mXL23mbJNW3/U6K+4pr1Hzoba7fCtN12zGbi/z9d/5GLLHemapgaccPBjOYCDJQIbPnoIdtQ08fTCYr46Id8lAXAjZ7Z8ABc8YEmgKxl1QfCitlmukG6qck0k7WUNdE0C7/zaNbscym8o4jp1Q0dHRVOk2tQ7mwhMv8cV6DtXuoJ86AUwPigAABe6SURBVFmuqcfXAM11rmbQe0zHSS+lJ0y+yT3CFZ/kztjD0XccXP2G6w9TdX1FHcXRIx8m33jg/Uy6zjW3zrnD1Wx8DXDlC3uTALi/z68945qeX/+R63OJgLASgYi8APwTeF1VAxGJ5Chw/zsb8AeU608LFhab5rkq7LhLYfzl0Q3O7Cs12xX8y19w7djgztg7Mvn7rqo/7pLOi88cXFwCXDEz2lEcWEyMa+Y5XKd8343Omvd7+MqD+3datxkRHGkVoes9wq1D3gd8DVgnIr8REc/daWVnTRNPf7yVrxyb52oDdTvh+Wuh52A450/RDs90ZOzFrvNwwQPu7DHtABf9xSfBCTMgObNz4zMG3Ai127a6CyQPJj4pYgNGwkoEqjpHVa8AjgM2A3NE5EMRuVpEukl99OD+Pm8jrQHlhtOHuH6B5691Izou/ld0rlA1n23ENNeJW1/u2pqN6aqiXIaE3askItnAVcC1wCfA3bjE8FZEIutCdte38OSCLZw/vh8De6bAO79xw8im/d6NCTZdU2K660gEN82FMaZD4fYRvAgMBx4Hpqtq25Uvz4pI9C/zjbCZRcU0+fz8oGALPHSLuxBl3GVunLjp2k66wY3DH9hFOnSN6YLCHTV0j6rO7WjBgYYjdRf+gDJz/nr+nfFb8l9b5sYJn/sXd5FHV7kU3hxY/+PhyuejHYUxXVq4TUOjRGRPT5qIZInIdz9rIxGZKiJrRGS9iNzWwfI/i8iS4GOtiFQdQuydYt7acgZUFzG6ZRmc/jP43iI3h013GapnjPG8cBPBdaq6p5BW1UrguoNtICKxwL3A2cAo4HIRGRW6jqrerKrjVXU88FfghUMJvjM8Pn8L05OWoAlpbrKxA81zY4wxR6lwE0GsyN52kGAh/1kl4iRgvapuVNUW4BngYANvLweeDjOeTlG8u4F31mzny7GLkSFn2JztxphuKdxE8AauY/gMETkDV2C/8Rnb5AHFIa9Lgu/tR0QGAoXAfw+wfIaIFIlIUXl5eZghH74nFmzhmJhNpPl2wfBzOu1zjTGmM4WbCH4EzAW+E3y8DfzwCMZxGTBLVTu8sa2qPqiqE1V1Ym7uQWZyPIKafH5mLixmRu5qN39L6Jz1xhjTjYQ1aig4rcT9wUe4SoH+Ia/zg+915DLg+kPYd8R9sH4XlQ0+vpj+sZvV0O7aZIzppsKqEYjIUBGZJSIrRWRj2+MzNlsIDBWRQhFJwBX2szvY9wggC/joUIOPpLdW7mBk4i5Sq9e5qWKNMaabCrdp6BFcbaAVOA14DHjiYBuoaitwA/AmsAqYqaorROQuETkvZNXLgGe0C82HHQgoc1bt5Npeq9wbIywRGGO6r3AvKEtW1bdFRFR1C3CniCwCfn6wjVT1NeC1du/9vN3rOw8h3k6xtKSKXXXNnNpjobuBRbTmlzfGmE4Qbo2gWURicLOP3iAiFwLddqa1/y7fyuVxc8nevRiGnx3tcIwxJqLCrRHcBKQANwK/xDUPfTNSQUWNKrz/J65ZeDdZcdXQe6y7itgYY7qxz0wEwYvHLlXVW4E6oPuWjBv+C2/fxaf+sdQf/z3Onn6JzSdkjOn2PrNpKDi2/5ROiCX6tn0CwPW+mxg9ebolAWOMJ4TbNPSJiMwGngPq295U1S43N9Bh2b6M7bF96de7NwOyU6IdjTHGdIpwE0ESUAGcHvKe0gUniTsc/m1LWewbwFmjekc7FGOM6TThXlncffsF2jRWEVu1meX+SZwxonOmsTDGmK4g3DuUPYKrAexDVa854hFFy/ZPAVgbM4jv59lNzI0x3hFu09CrIc+TgAuBbUc+nCjavgyA2H7HkBAX9q2cjTHmqBdu09A+9/oTkaeB9yMSUZT4SpdQoVkMGzw42qEYY0yn+rynvkOBXkcykGhrKf6EFYECji+wWUaNMd4Sbh9BLfv2EWzH3aOge2hpILl6Ayv1PK4aYP0DxhhvCbdpKD3SgUTVzpXEEKAmcxTpSXZTemOMt4R7P4ILRaRHyOtMEbkgcmF1Lv+2JQCkDpwQ5UiMMabzhdtHcIeqVre9UNUq4I7IhNT5KjcUUaWpDBs+KtqhGGNMpws3EXS0XrhDT7s83baUFYECJhZaR7ExxnvCTQRFIvInERkcfPwJWBTJwDqN30dm3TpKEofQKz0p2tEYY0ynCzcRfA9oAZ4FngGa6GI3m/+8tHw18eqjtffYaIdijDFREe6ooXrgtgjHEhWVRc/TE+gx7ORoh2KMMVER7qiht0QkM+R1loi8GbmwOklzHWlL/8l//BMYOnxctKMxxpioCLdpKCc4UggAVa2kO1xZvPhREnw13N96Hv17Jkc7GmOMiYpwE0FARAa0vRCRAjqYjfSo0toMH/6NjanHsjVlNCkJ3WYQlDHGHJJwS7+fAO+LyLuAAF8AZkQsqs6wbCbUbuP53BvIS7bagDHGu8KqEajqG8BEYA3wNHAL0BjBuCIr4IcP/gJ9xvFG4yjysywRGGO8K9zO4muBt3EJ4FbgceDOyIUVYevnQMV69JSbKalqIj/L7k9sjPGucPsIbgKOB7ao6mnAsUDVwTfpwnauBKCi76k0twbIy7QagTHGu8JNBE2q2gQgIomquhoYHrmwIqymDBIzKGmIBbCmIWOMp4XbWVwSvI7gJeAtEakEtkQurAir3QbpfSmpbACwpiFjjKeFe2XxhcGnd4rIXKAH8EbEooq0mjLI6EtJpevvzrMagTHGww75VpWq+q6qzlbVls9aV0SmisgaEVkvIh1OUSEil4jIShFZISJPHWo8n0vNNkjvR2llI5kp8aQl2jUExhjvilgJKCKxwL3AWUAJsFBEZqvqypB1hgK3A5NVtVJEIn+1csAPdTtcjWBrg/UPGGM87/PevD4ck4D1qroxWHt4Bji/3TrXAfcGp6xAVXdGMB6nbieoHzL6UVLZaCOGjDGeF8lEkAcUh7wuCb4XahgwTEQ+EJH5IjK1ox2JyAwRKRKRovLy8sOLqnYbAJrel9KqRusoNsZ4XiQTQTjigKHAFOBy4B+hs5y2UdUHVXWiqk7Mzc09vE+sKXP/xPeiocVvTUPGGM+LZCIoBfqHvM4PvheqBJitqj5V3QSsxSWGyKl1iaDU3wPAmoaMMZ4XyUSwEBgqIoUikgBcBsxut85LuNoAIpKDayraGMGYoKYUYuLY0pQK2DUExhgTsUSgqq3ADcCbwCpgpqquEJG7ROS84GpvAhUishKYC/yvqlZEKibANQ2l9aGkqhmwawiMMSaiA+hV9TXgtXbv/TzkuQI/CD46R+224IihBtKT4uiRHN9pH22MMV1RtDuLO1/wqmIbMWSMMY73EkFtGaS7awhsxJAxxngtETTVQEsdmt7XLiYzxpggbyWCGncxWWNSL+qaW61GYIwxeC0RBK8q3k5PwIaOGmMMeC0RBK8qLm7NAuyGNMYYA15LBMEawbbgVcW90hOjGY0xxnQJ3koENWWQnEVNq7t8Ii3J7kNgjDHeSgTBoaP1za3ECCTHx0Y7ImOMiTpvJYKabZDRl7pmP6kJcYhItCMyxpio814iSO9LXbOPVLs9pTHGAF5KBH4f1JdDRh71zX5SE61ZyBhjwEuJoHY7oMGmoVa7Yb0xxgR5KBG4awjaOoutacgYYxzvJILg9BJWIzDGmH15JxGE1AgsERhjzF7eSQR9xsHJ34OUntY0ZIwxIbxTGhZMdg8IjhryzqEbY8zBeKdGENTSGqDFHyDNho8aYwzgwURQ39wKYDUCY4wJ8lwiqAsmAussNsYYxxKBMcZ4nOcSgTUNGWPMvjyXCOosERhjzD48lwjqm/2ANQ0ZY0wbDyaCthqBDR81xhjwYCKwzmJjjNmXZxOB9REYY4zjuURQ39xKYlwM8bGeO3RjjOlQREtDEZkqImtEZL2I3NbB8qtEpFxElgQf10YyHsBmHjXGmHYiViKKSCxwL3AWUAIsFJHZqrqy3arPquoNkYqjPZt51Bhj9hXJGsEkYL2qblTVFuAZ4PwIfl5Y6mzmUWOM2UckE0EeUBzyuiT4XnsXicgyEZklIv072pGIzBCRIhEpKi8vP6yg6ptbbeZRY4wJEe0e01eAAlUdB7wFPNrRSqr6oKpOVNWJubm5h/WBddY0ZIwx+4hkIigFQs/w84Pv7aGqFaraHHz5EDAhgvEAbTUCSwTGGNMmkolgITBURApFJAG4DJgduoKI9A15eR6wKoLxADZqyBhj2otYiaiqrSJyA/AmEAs8rKorROQuoEhVZwM3ish5QCuwG7gqUvG0sVFDxhizr4iWiKr6GvBau/d+HvL8duD2SMYQKhBQ6lts1JAxxoTyVInY4GubedRGDRnjNT6fj5KSEpqamqIdSkQlJSWRn59PfHx82Nt4KhHUNdk8Q8Z4VUlJCenp6RQUFCAi0Q4nIlSViooKSkpKKCwsDHu7aA8f7VQ286gx3tXU1ER2dna3TQIAIkJ2dvYh13o8lQjqLREY42ndOQm0+TzH6MlEYE1Dxhizl6cSgTUNGWOipaqqivvuu++Qt5s2bRpVVVURiGgvTyWC+harERhjouNAiaC1tfWg27322mtkZmZGKizAs6OGbPioMV72i1dWsHJbzRHd56h+GdwxffQBl992221s2LCB8ePHEx8fT1JSEllZWaxevZq1a9dywQUXUFxcTFNTEzfddBMzZswAoKCggKKiIurq6jj77LM55ZRT+PDDD8nLy+Pll18mOTn5sGP3VI2grrntOgJP5T9jTBfwm9/8hsGDB7NkyRJ+//vfs3jxYu6++27Wrl0LwMMPP8yiRYsoKirinnvuoaKiYr99rFu3juuvv54VK1aQmZnJ888/f0Ri81SJWN/cSoxAcrzVCIzxsoOduXeWSZMm7TPW/5577uHFF18EoLi4mHXr1pGdnb3PNoWFhYwfPx6ACRMmsHnz5iMSi6cSQdsU1F4YQmaM6dpSU1P3PH/nnXeYM2cOH330ESkpKUyZMqXDawESExP3PI+NjaWxsfGIxOKppiGbgtoYEy3p6enU1tZ2uKy6upqsrCxSUlJYvXo18+fP79TYPFUq2k1pjDHRkp2dzeTJkxkzZgzJycn07t17z7KpU6fywAMPMHLkSIYPH86JJ57YqbF5qlS0RGCMiaannnqqw/cTExN5/fXXO1zW1g+Qk5PD8uXL97x/6623HrG4PNg0ZB3FxhgTymOJwE9qgtUIjDEmlKcSQV1zK2lJlgiMMSaUpxJBfYuNGjLGmPY8kwhUlbom6yw2xpj2PJMImlsDtAbUagTGGNOOZxLBnnsRJNioIWNM15eWltZpn+WhROAmnLOmIWOM2ZdnSsW2m9Kk26ghY8zrt8H2T4/sPvuMhbN/c8DFt912G/379+f6668H4M477yQuLo65c+dSWVmJz+fjV7/6Feeff/6RjSsM3qkR2E1pjDFRdOmllzJz5sw9r2fOnMk3v/lNXnzxRRYvXszcuXO55ZZbUNVOj80zpeLem9J45pCNMQdykDP3SDn22GPZuXMn27Zto7y8nKysLPr06cPNN9/MvHnziImJobS0lB07dtCnT59Ojc0zpaLdr9gYE20XX3wxs2bNYvv27Vx66aU8+eSTlJeXs2jRIuLj4ykoKOhw+ulI80ypuGfUkCUCY0yUXHrppVx33XXs2rWLd999l5kzZ9KrVy/i4+OZO3cuW7ZsiUpcnikV99QIbK4hY0yUjB49mtraWvLy8ujbty9XXHEF06dPZ+zYsUycOJERI0ZEJS7PlIoDeqYwdXQfu3G9MSaqPv1072ilnJwcPvroow7Xq6ur66yQvJMIvjS6D18a3bkdMMYYczSI6PBREZkqImtEZL2I3HaQ9S4SERWRiZGMxxhjzP4ilghEJBa4FzgbGAVcLiKjOlgvHbgJWBCpWIwxBojKGP3O9nmOMZI1gknAelXdqKotwDNAR5fM/RL4LdD5Y6aMMZ6RlJRERUVFt04GqkpFRQVJSUmHtF0k+wjygOKQ1yXACaEriMhxQH9V/beI/O+BdiQiM4AZAAMGDIhAqMaY7i4/P5+SkhLKy8ujHUpEJSUlkZ+ff0jbRK2zWERigD8BV33Wuqr6IPAgwMSJE7tvOjfGREx8fDyFhYXRDqNLimTTUCnQP+R1fvC9NunAGOAdEdkMnAjMtg5jY4zpXJFMBAuBoSJSKCIJwGXA7LaFqlqtqjmqWqCqBcB84DxVLYpgTMYYY9qJWCJQ1VbgBuBNYBUwU1VXiMhdInJepD7XGGPMoZGjrQddRMqBzzshRw6w6wiGc7Tw4nF78ZjBm8ftxWOGQz/ugaqa29GCoy4RHA4RKVJVz/VBePG4vXjM4M3j9uIxw5E9bs/cmMYYY0zHLBEYY4zHeS0RPBjtAKLEi8ftxWMGbx63F48ZjuBxe6qPwBhjzP68ViMwxhjTjiUCY4zxOM8kgnDvjXA0E5H+IjJXRFaKyAoRuSn4fk8ReUtE1gX/zYp2rEeaiMSKyCci8mrwdaGILAj+3s8Gr27vVkQkU0RmichqEVklIid55Le+Ofj3vVxEnhaRpO72e4vIwyKyU0SWh7zX4W8rzj3BY18WnMzzkHgiEYR7b4RuoBW4RVVH4eZuuj54nLcBb6vqUODt4Ovu5ibcFextfgv8WVWHAJXAt6ISVWTdDbyhqiOAY3DH361/axHJA24EJqrqGCAWN31Nd/u9/wVMbffegX7bs4GhwccM4P5D/TBPJALCvzfCUU1Vy1R1cfB5La5gyMMd66PB1R4FLohOhJEhIvnAOcBDwdcCnA7MCq7SHY+5B/BF4J8AqtqiqlV08986KA5IFpE4IAUoo5v93qo6D9jd7u0D/bbnA4+pMx/IFJG+h/J5XkkEHd0bIS9KsXQKESkAjsXd+a23qpYFF20HekcprEj5C/BDIBB8nQ1UBee7gu75excC5cAjwSaxh0QklW7+W6tqKfAHYCsuAVQDi+j+vzcc+Lc97PLNK4nAU0QkDXge+L6q1oQuUzdeuNuMGRaRc4Gdqroo2rF0sjjgOOB+VT0WqKddM1B3+60Bgu3i5+MSYT8glf2bULq9I/3beiURfNa9EboNEYnHJYEnVfWF4Ns72qqKwX93Riu+CJgMnBe8p8UzuCaCu3HV47YbL3XH37sEKFHVtnt9z8Ilhu78WwOcCWxS1XJV9QEv4P4GuvvvDQf+bQ+7fPNKIjjovRG6i2Db+D+BVar6p5BFs4FvBp9/E3i5s2OLFFW9XVXzg/e0uAz4r6peAcwFvhpcrVsdM4CqbgeKRWR48K0zgJV04986aCtwooikBP/e2467W//eQQf6bWcD3wiOHjoRqA5pQgqPqnriAUwD1gIbgJ9EO54IHeMpuOriMmBJ8DEN12b+NrAOmAP0jHasETr+KcCrweeDgI+B9cBzQGK044vA8Y4HioK/90tAlhd+a+AXwGpgOfA4kNjdfm/gaVwfiA9X+/vWgX5bQHCjIjcAn+JGVB3S59kUE8YY43FeaRoyxhhzAJYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwJhOJCJT2mZINaarsERgjDEeZ4nAmA6IyJUi8rGILBGRvwfvd1AnIn8OzoX/tojkBtcdLyLzg3PBvxgyT/wQEZkjIktFZLGIDA7uPi3kPgJPBq+QNSZqLBEY046IjAQuBSar6njAD1yBm+CsSFVHA+8CdwQ3eQz4kaqOw13Z2fb+k8C9qnoMcDLuSlFws8J+H3dvjEG4uXKMiZq4z17FGM85A5gALAyerCfjJvgKAM8G13kCeCF4X4BMVX03+P6jwHMikg7kqeqLAKraBBDc38eqWhJ8vQQoAN6P/GEZ0zFLBMbsT4BHVfX2fd4U+Vm79T7v/CzNIc/92P9DE2XWNGTM/t4GvioivWDPvWIH4v6/tM1w+TXgfVWtBipF5AvB978OvKvuDnElInJBcB+JIpLSqUdhTJjsTMSYdlR1pYj8FPiPiMTgZoC8Hnfzl0nBZTtx/QjgpgR+IFjQbwSuDr7/deDvInJXcB8Xd+JhGBM2m33UmDCJSJ2qpkU7DmOONGsaMsYYj7MagTHGeJzVCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzu/wOLo1Jf8UKlTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBZEPQp66AUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61727a2e-a3ca-455e-d645-c1ce250be020"
      },
      "source": [
        "acc_value=model.evaluate(test_x_r,test_y_r)\n",
        "print(\"Test Accuracy \", acc_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2254 - accuracy: 0.7258\n",
            "Test Accuracy  [1.225420355796814, 0.7257999777793884]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clObzkU7nFWw",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of CNN model with CIFAR dataset is 72.5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NTjVIUkmv7S",
        "colab_type": "text"
      },
      "source": [
        "####  Training  ResNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8BZueuk6__O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_r = tf.data.Dataset.from_tensor_slices((train_x_r, train_y_r))\n",
        "train_dataset_r = train_dataset_r.shuffle(buffer_size=10000).batch(batch_size=128).repeat()\n",
        "test_dataset_r = tf.data.Dataset.from_tensor_slices((test_x_r, test_y_r))\n",
        "test_dataset_r = test_dataset_r.shuffle(buffer_size=10000).batch(batch_size=128).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcOFbrse8Ps0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen_r = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)\n",
        "data_r= ImageDataGenerator()\n",
        "train_gen_r= datagen_r.flow(train_x_r, train_y_r, batch_size=128)\n",
        "test_gen_r= data_r.flow(test_x_r, test_y_r, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRNxSJN98ZUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model_r_1 = Sequential()\n",
        "  model_r_1.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                          input_shape=(32,32,3)))\n",
        "  model_r_1.add(layers.MaxPooling2D((2, 2)))\n",
        "  model_r_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model_r_1.add(layers.MaxPooling2D((2, 2)))\n",
        "  model_r_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model_r_1.add(layers.MaxPooling2D((2, 2)))\n",
        "  model_r_1.add(layers.Flatten())\n",
        "  model_r_1.add(layers.Dropout(0.2))\n",
        "  model_r_1.add(layers.Dense(128, activation='relu'))\n",
        "  model_r_1.add(layers.Dense(10, activation='sigmoid'))\n",
        "\n",
        "  model_r_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYcuflrW9Z7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a5c172f-e927-4516-f254-f0fb057b55c4"
      },
      "source": [
        "Epochs=100\n",
        "STEPS_PER_EPOCH=50\n",
        "\n",
        "history=model_r_1.fit(train_gen_r, epochs=Epochs,validation_data=test_gen_r,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 2.2978 - accuracy: 0.1214 - val_loss: 2.2902 - val_accuracy: 0.1806\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 2.2780 - accuracy: 0.1475 - val_loss: 2.2454 - val_accuracy: 0.1928\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 2.2254 - accuracy: 0.1744 - val_loss: 2.1853 - val_accuracy: 0.1983\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 2.1772 - accuracy: 0.1991 - val_loss: 2.0845 - val_accuracy: 0.2248\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 2.1270 - accuracy: 0.2205 - val_loss: 2.0360 - val_accuracy: 0.2602\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 2.0724 - accuracy: 0.2384 - val_loss: 2.0459 - val_accuracy: 0.2598\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 2.0290 - accuracy: 0.2492 - val_loss: 2.0411 - val_accuracy: 0.2745\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.9962 - accuracy: 0.2695 - val_loss: 1.9361 - val_accuracy: 0.2947\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.9613 - accuracy: 0.2947 - val_loss: 1.8550 - val_accuracy: 0.3158\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.8910 - accuracy: 0.3136 - val_loss: 2.0799 - val_accuracy: 0.2688\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.8814 - accuracy: 0.3305 - val_loss: 1.7878 - val_accuracy: 0.3753\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.8157 - accuracy: 0.3475 - val_loss: 1.8783 - val_accuracy: 0.3153\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.8110 - accuracy: 0.3449 - val_loss: 1.7704 - val_accuracy: 0.3656\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.7646 - accuracy: 0.3617 - val_loss: 1.6642 - val_accuracy: 0.4212\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.7224 - accuracy: 0.3802 - val_loss: 1.5928 - val_accuracy: 0.4234\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.6800 - accuracy: 0.3931 - val_loss: 1.5755 - val_accuracy: 0.4409\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.6564 - accuracy: 0.4017 - val_loss: 1.5489 - val_accuracy: 0.4589\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.6374 - accuracy: 0.4131 - val_loss: 1.5755 - val_accuracy: 0.4241\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.6250 - accuracy: 0.4172 - val_loss: 1.4937 - val_accuracy: 0.4636\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.5801 - accuracy: 0.4217 - val_loss: 1.7224 - val_accuracy: 0.3831\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.5512 - accuracy: 0.4422 - val_loss: 1.4811 - val_accuracy: 0.4556\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.5252 - accuracy: 0.4508 - val_loss: 1.4625 - val_accuracy: 0.4809\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.5418 - accuracy: 0.4389 - val_loss: 1.4103 - val_accuracy: 0.4966\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.5290 - accuracy: 0.4519 - val_loss: 1.4582 - val_accuracy: 0.4692\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.4894 - accuracy: 0.4655 - val_loss: 1.4135 - val_accuracy: 0.4945\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.4739 - accuracy: 0.4670 - val_loss: 1.4446 - val_accuracy: 0.4811\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.4677 - accuracy: 0.4702 - val_loss: 1.4499 - val_accuracy: 0.4850\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.4510 - accuracy: 0.4767 - val_loss: 1.3899 - val_accuracy: 0.4942\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.4842 - accuracy: 0.4696 - val_loss: 1.3614 - val_accuracy: 0.5075\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.4471 - accuracy: 0.4812 - val_loss: 1.3972 - val_accuracy: 0.4877\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.3992 - accuracy: 0.4986 - val_loss: 1.3807 - val_accuracy: 0.5131\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.4065 - accuracy: 0.4914 - val_loss: 1.3407 - val_accuracy: 0.5180\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.3787 - accuracy: 0.5047 - val_loss: 1.3222 - val_accuracy: 0.5258\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.3801 - accuracy: 0.5058 - val_loss: 1.2698 - val_accuracy: 0.5541\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 1.3764 - accuracy: 0.5028 - val_loss: 1.3315 - val_accuracy: 0.5209\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.3612 - accuracy: 0.5144 - val_loss: 1.2999 - val_accuracy: 0.5367\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.3526 - accuracy: 0.5188 - val_loss: 1.3114 - val_accuracy: 0.5431\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.3317 - accuracy: 0.5231 - val_loss: 1.3274 - val_accuracy: 0.5094\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.3469 - accuracy: 0.5180 - val_loss: 1.2293 - val_accuracy: 0.5611\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.3165 - accuracy: 0.5267 - val_loss: 1.2092 - val_accuracy: 0.5652\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.3246 - accuracy: 0.5287 - val_loss: 1.2349 - val_accuracy: 0.5530\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.3112 - accuracy: 0.5242 - val_loss: 1.2393 - val_accuracy: 0.5695\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.3091 - accuracy: 0.5294 - val_loss: 1.2731 - val_accuracy: 0.5464\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 1.2690 - accuracy: 0.5494 - val_loss: 1.2305 - val_accuracy: 0.5714\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.2868 - accuracy: 0.5394 - val_loss: 1.2249 - val_accuracy: 0.5675\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.2458 - accuracy: 0.5669 - val_loss: 1.2195 - val_accuracy: 0.5566\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.2838 - accuracy: 0.5441 - val_loss: 1.2019 - val_accuracy: 0.5764\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.2376 - accuracy: 0.5653 - val_loss: 1.2534 - val_accuracy: 0.5520\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.2591 - accuracy: 0.5578 - val_loss: 1.1426 - val_accuracy: 0.5900\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.2170 - accuracy: 0.5689 - val_loss: 1.1923 - val_accuracy: 0.5764\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.2393 - accuracy: 0.5609 - val_loss: 1.1527 - val_accuracy: 0.5984\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.2182 - accuracy: 0.5686 - val_loss: 1.1783 - val_accuracy: 0.5786\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.2245 - accuracy: 0.5655 - val_loss: 1.0910 - val_accuracy: 0.6119\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1875 - accuracy: 0.5852 - val_loss: 1.1179 - val_accuracy: 0.5977\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1762 - accuracy: 0.5806 - val_loss: 1.1923 - val_accuracy: 0.5888\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.1873 - accuracy: 0.5817 - val_loss: 1.1125 - val_accuracy: 0.6048\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1963 - accuracy: 0.5719 - val_loss: 1.2753 - val_accuracy: 0.5578\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1674 - accuracy: 0.5911 - val_loss: 1.1149 - val_accuracy: 0.6028\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1923 - accuracy: 0.5773 - val_loss: 1.1445 - val_accuracy: 0.5959\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1552 - accuracy: 0.6027 - val_loss: 1.0853 - val_accuracy: 0.6111\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1626 - accuracy: 0.5847 - val_loss: 1.2102 - val_accuracy: 0.5756\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1496 - accuracy: 0.6016 - val_loss: 1.0962 - val_accuracy: 0.6141\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1352 - accuracy: 0.5991 - val_loss: 1.0563 - val_accuracy: 0.6303\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1238 - accuracy: 0.6117 - val_loss: 1.1046 - val_accuracy: 0.6122\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1366 - accuracy: 0.5986 - val_loss: 1.0594 - val_accuracy: 0.6288\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1076 - accuracy: 0.6102 - val_loss: 1.0726 - val_accuracy: 0.6230\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1303 - accuracy: 0.6063 - val_loss: 1.0468 - val_accuracy: 0.6347\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1329 - accuracy: 0.5944 - val_loss: 1.0743 - val_accuracy: 0.6178\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.1149 - accuracy: 0.6037 - val_loss: 1.0780 - val_accuracy: 0.6150\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.1262 - accuracy: 0.5997 - val_loss: 1.1316 - val_accuracy: 0.6070\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0796 - accuracy: 0.6175 - val_loss: 1.0276 - val_accuracy: 0.6383\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0707 - accuracy: 0.6308 - val_loss: 1.0660 - val_accuracy: 0.6230\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0850 - accuracy: 0.6214 - val_loss: 1.0915 - val_accuracy: 0.6144\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0723 - accuracy: 0.6194 - val_loss: 1.0442 - val_accuracy: 0.6369\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0881 - accuracy: 0.6130 - val_loss: 1.0539 - val_accuracy: 0.6273\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0626 - accuracy: 0.6234 - val_loss: 1.0209 - val_accuracy: 0.6400\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0852 - accuracy: 0.6192 - val_loss: 1.0084 - val_accuracy: 0.6525\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0453 - accuracy: 0.6300 - val_loss: 1.0730 - val_accuracy: 0.6239\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0702 - accuracy: 0.6202 - val_loss: 1.0083 - val_accuracy: 0.6416\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0745 - accuracy: 0.6261 - val_loss: 1.0071 - val_accuracy: 0.6450\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0354 - accuracy: 0.6477 - val_loss: 0.9647 - val_accuracy: 0.6641\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0453 - accuracy: 0.6295 - val_loss: 0.9769 - val_accuracy: 0.6609\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0482 - accuracy: 0.6289 - val_loss: 0.9978 - val_accuracy: 0.6528\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0616 - accuracy: 0.6308 - val_loss: 0.9935 - val_accuracy: 0.6514\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0270 - accuracy: 0.6334 - val_loss: 1.0188 - val_accuracy: 0.6409\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0086 - accuracy: 0.6466 - val_loss: 0.9655 - val_accuracy: 0.6559\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 1.0195 - accuracy: 0.6381 - val_loss: 0.9841 - val_accuracy: 0.6459\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0273 - accuracy: 0.6441 - val_loss: 0.9661 - val_accuracy: 0.6628\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0262 - accuracy: 0.6319 - val_loss: 0.9917 - val_accuracy: 0.6505\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0156 - accuracy: 0.6452 - val_loss: 0.9400 - val_accuracy: 0.6758\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.9997 - accuracy: 0.6516 - val_loss: 0.9496 - val_accuracy: 0.6680\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 1.0303 - accuracy: 0.6397 - val_loss: 1.0101 - val_accuracy: 0.6522\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0130 - accuracy: 0.6494 - val_loss: 0.9233 - val_accuracy: 0.6798\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.9997 - accuracy: 0.6461 - val_loss: 0.9717 - val_accuracy: 0.6592\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.9926 - accuracy: 0.6548 - val_loss: 1.0016 - val_accuracy: 0.6498\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 1.0019 - accuracy: 0.6491 - val_loss: 1.0519 - val_accuracy: 0.6366\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.9689 - accuracy: 0.6628 - val_loss: 0.9243 - val_accuracy: 0.6777\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.9616 - accuracy: 0.6656 - val_loss: 0.9338 - val_accuracy: 0.6733\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.9952 - accuracy: 0.6467 - val_loss: 0.9104 - val_accuracy: 0.6797\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.9934 - accuracy: 0.6548 - val_loss: 0.9871 - val_accuracy: 0.6516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4dKXWyg_9rz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b638b495-4746-4086-f254-7af0d7ecd906"
      },
      "source": [
        "acc_value=model_r_1.evaluate(test_x_r,test_y_r)\n",
        "print(\"Accuracy of the Resnet is \",acc_value[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.9870 - accuracy: 0.6499\n",
            "Accuracy of the Resnet is  0.6499000191688538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFNjA3imnRYs",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of Resnet model is 64.9%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6ZBiECzS75",
        "colab_type": "text"
      },
      "source": [
        "### Training of ResNet using learning rate schedule\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx267_8GA45F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_learning_rate = 0.1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,decay_steps=100000,decay_rate=0.96,staircase=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-oFBVA2CV7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_r.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506yEF16CHJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93126589-3a1d-48a7-8a2a-582ed70dfba4"
      },
      "source": [
        "Epochs=100\n",
        "history=model_r.fit(train_gen_r, epochs=Epochs,validation_data=test_gen_r,\n",
        "                  steps_per_epoch=STEPS_PER_EPOCH,validation_steps=50,verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 11.3515 - accuracy: 0.1111 - val_loss: 11.5559 - val_accuracy: 0.1022\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5536 - accuracy: 0.1003 - val_loss: 11.5583 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6193 - accuracy: 0.0969 - val_loss: 11.6122 - val_accuracy: 0.1008\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 11.8258 - accuracy: 0.0908 - val_loss: 11.6428 - val_accuracy: 0.0997\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.7061 - accuracy: 0.1008 - val_loss: 11.5841 - val_accuracy: 0.1002\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.7085 - accuracy: 0.0986 - val_loss: 11.6263 - val_accuracy: 0.1005\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5254 - accuracy: 0.1022 - val_loss: 11.5817 - val_accuracy: 0.1030\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6240 - accuracy: 0.0981 - val_loss: 11.5770 - val_accuracy: 0.0991\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5794 - accuracy: 0.0998 - val_loss: 11.6240 - val_accuracy: 0.1044\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6944 - accuracy: 0.0920 - val_loss: 11.6498 - val_accuracy: 0.0988\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5911 - accuracy: 0.0952 - val_loss: 11.5559 - val_accuracy: 0.0998\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6568 - accuracy: 0.0969 - val_loss: 11.6568 - val_accuracy: 0.0994\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6169 - accuracy: 0.0994 - val_loss: 11.5770 - val_accuracy: 0.1020\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.7413 - accuracy: 0.0967 - val_loss: 11.5700 - val_accuracy: 0.1006\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6287 - accuracy: 0.0939 - val_loss: 11.6474 - val_accuracy: 0.0962\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6521 - accuracy: 0.1055 - val_loss: 11.5700 - val_accuracy: 0.1008\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6545 - accuracy: 0.0950 - val_loss: 11.6005 - val_accuracy: 0.0989\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5090 - accuracy: 0.1066 - val_loss: 11.5770 - val_accuracy: 0.1027\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5301 - accuracy: 0.1000 - val_loss: 11.6850 - val_accuracy: 0.1020\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 11.6498 - accuracy: 0.0984 - val_loss: 11.5442 - val_accuracy: 0.1013\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6263 - accuracy: 0.1033 - val_loss: 11.6686 - val_accuracy: 0.1017\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6193 - accuracy: 0.0984 - val_loss: 11.6381 - val_accuracy: 0.0969\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5653 - accuracy: 0.1022 - val_loss: 11.6122 - val_accuracy: 0.1020\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.4996 - accuracy: 0.1014 - val_loss: 11.6193 - val_accuracy: 0.1025\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6302 - accuracy: 0.0949 - val_loss: 11.6733 - val_accuracy: 0.0972\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6428 - accuracy: 0.0995 - val_loss: 11.6287 - val_accuracy: 0.1023\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6122 - accuracy: 0.1011 - val_loss: 11.6076 - val_accuracy: 0.0977\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6850 - accuracy: 0.0970 - val_loss: 11.5888 - val_accuracy: 0.0997\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5653 - accuracy: 0.0989 - val_loss: 11.6474 - val_accuracy: 0.1020\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.4954 - accuracy: 0.1026 - val_loss: 11.6005 - val_accuracy: 0.1014\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.7272 - accuracy: 0.1034 - val_loss: 11.5489 - val_accuracy: 0.1003\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5372 - accuracy: 0.0998 - val_loss: 11.6451 - val_accuracy: 0.1025\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5231 - accuracy: 0.1008 - val_loss: 11.6169 - val_accuracy: 0.0975\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6122 - accuracy: 0.0970 - val_loss: 11.4996 - val_accuracy: 0.1048\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6137 - accuracy: 0.0962 - val_loss: 11.6521 - val_accuracy: 0.0989\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5677 - accuracy: 0.1053 - val_loss: 11.6076 - val_accuracy: 0.0991\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5559 - accuracy: 0.1025 - val_loss: 11.6357 - val_accuracy: 0.0972\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5817 - accuracy: 0.1002 - val_loss: 11.6287 - val_accuracy: 0.0981\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5841 - accuracy: 0.0938 - val_loss: 11.5325 - val_accuracy: 0.0984\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5935 - accuracy: 0.0980 - val_loss: 11.5653 - val_accuracy: 0.1013\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5019 - accuracy: 0.0955 - val_loss: 11.6920 - val_accuracy: 0.1005\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5911 - accuracy: 0.1003 - val_loss: 11.6545 - val_accuracy: 0.0947\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6263 - accuracy: 0.0995 - val_loss: 11.5747 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5911 - accuracy: 0.1016 - val_loss: 11.5794 - val_accuracy: 0.1022\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5817 - accuracy: 0.0986 - val_loss: 11.6662 - val_accuracy: 0.0989\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5442 - accuracy: 0.0989 - val_loss: 11.6920 - val_accuracy: 0.0992\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6451 - accuracy: 0.0975 - val_loss: 11.5841 - val_accuracy: 0.1013\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6639 - accuracy: 0.0986 - val_loss: 11.5935 - val_accuracy: 0.1013\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.7038 - accuracy: 0.0962 - val_loss: 11.6498 - val_accuracy: 0.1008\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5465 - accuracy: 0.0991 - val_loss: 11.5043 - val_accuracy: 0.1027\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6991 - accuracy: 0.0991 - val_loss: 11.6592 - val_accuracy: 0.0994\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.4926 - accuracy: 0.1063 - val_loss: 11.6169 - val_accuracy: 0.0984\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6917 - accuracy: 0.0998 - val_loss: 11.6592 - val_accuracy: 0.0991\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6498 - accuracy: 0.0998 - val_loss: 11.5888 - val_accuracy: 0.1008\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5747 - accuracy: 0.0991 - val_loss: 11.6709 - val_accuracy: 0.0972\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6873 - accuracy: 0.0986 - val_loss: 11.6873 - val_accuracy: 0.1008\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6099 - accuracy: 0.0991 - val_loss: 11.6780 - val_accuracy: 0.0967\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5888 - accuracy: 0.0992 - val_loss: 11.6381 - val_accuracy: 0.1006\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5724 - accuracy: 0.0970 - val_loss: 11.6709 - val_accuracy: 0.0989\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6334 - accuracy: 0.0977 - val_loss: 11.5935 - val_accuracy: 0.1031\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5653 - accuracy: 0.1025 - val_loss: 11.5841 - val_accuracy: 0.1016\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6122 - accuracy: 0.0995 - val_loss: 11.6686 - val_accuracy: 0.0997\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6146 - accuracy: 0.1013 - val_loss: 11.5817 - val_accuracy: 0.1014\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.7930 - accuracy: 0.0905 - val_loss: 11.5794 - val_accuracy: 0.0991\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5841 - accuracy: 0.1017 - val_loss: 11.6076 - val_accuracy: 0.0967\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.7061 - accuracy: 0.0931 - val_loss: 11.5606 - val_accuracy: 0.1003\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.7413 - accuracy: 0.0923 - val_loss: 11.5137 - val_accuracy: 0.1016\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5465 - accuracy: 0.1017 - val_loss: 11.6099 - val_accuracy: 0.0984\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6326 - accuracy: 0.0965 - val_loss: 11.5794 - val_accuracy: 0.1014\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.6615 - accuracy: 0.1020 - val_loss: 11.6545 - val_accuracy: 0.0986\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6756 - accuracy: 0.1016 - val_loss: 11.5841 - val_accuracy: 0.1041\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6920 - accuracy: 0.0995 - val_loss: 11.5301 - val_accuracy: 0.1039\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5522 - accuracy: 0.1004 - val_loss: 11.6615 - val_accuracy: 0.0988\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6662 - accuracy: 0.0998 - val_loss: 11.6733 - val_accuracy: 0.0953\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5231 - accuracy: 0.1016 - val_loss: 11.6920 - val_accuracy: 0.1000\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6005 - accuracy: 0.0980 - val_loss: 11.6381 - val_accuracy: 0.0994\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6803 - accuracy: 0.0958 - val_loss: 11.5583 - val_accuracy: 0.1047\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5348 - accuracy: 0.1000 - val_loss: 11.6169 - val_accuracy: 0.1003\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.4973 - accuracy: 0.1020 - val_loss: 11.6357 - val_accuracy: 0.0975\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5207 - accuracy: 0.1031 - val_loss: 11.6334 - val_accuracy: 0.0997\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6404 - accuracy: 0.0992 - val_loss: 11.5817 - val_accuracy: 0.1016\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5747 - accuracy: 0.1003 - val_loss: 11.5700 - val_accuracy: 0.1006\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.4926 - accuracy: 0.1013 - val_loss: 11.6521 - val_accuracy: 0.0962\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.5418 - accuracy: 0.1008 - val_loss: 11.6240 - val_accuracy: 0.1005\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.5747 - accuracy: 0.1013 - val_loss: 11.6404 - val_accuracy: 0.0991\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 11.6099 - accuracy: 0.1006 - val_loss: 11.6005 - val_accuracy: 0.0992\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6920 - accuracy: 0.0975 - val_loss: 11.5606 - val_accuracy: 0.1008\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5630 - accuracy: 0.1000 - val_loss: 11.5418 - val_accuracy: 0.0981\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6122 - accuracy: 0.1016 - val_loss: 11.5864 - val_accuracy: 0.0995\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5380 - accuracy: 0.1022 - val_loss: 11.6240 - val_accuracy: 0.1005\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.4949 - accuracy: 0.1116 - val_loss: 11.6146 - val_accuracy: 0.1002\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5864 - accuracy: 0.0955 - val_loss: 11.5982 - val_accuracy: 0.0977\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5465 - accuracy: 0.0972 - val_loss: 11.6146 - val_accuracy: 0.1002\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5066 - accuracy: 0.1030 - val_loss: 11.6193 - val_accuracy: 0.1005\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5512 - accuracy: 0.1069 - val_loss: 11.6615 - val_accuracy: 0.0931\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.5958 - accuracy: 0.0998 - val_loss: 11.6334 - val_accuracy: 0.0944\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.7038 - accuracy: 0.0988 - val_loss: 11.6709 - val_accuracy: 0.1000\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 11.6029 - accuracy: 0.1009 - val_loss: 11.5418 - val_accuracy: 0.1003\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.6657 - accuracy: 0.0952 - val_loss: 11.6381 - val_accuracy: 0.1005\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 11.5583 - accuracy: 0.0988 - val_loss: 11.6357 - val_accuracy: 0.0986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-uujZZMCst8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5ec746a2-dcd4-4661-f4f2-093a8cd86aac"
      },
      "source": [
        "acc_value=model_r.evaluate(test_x_r,test_y_r)\n",
        "print(\"Accuracy of the Resnet is \",acc_value[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 11.6123 - accuracy: 0.1000\n",
            "Accuracy of the Resnet is  0.10000000149011612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCgExE4pnZWk",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of Renet model with Lookahead optimiser is 10%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AGdWDfYnjEo",
        "colab_type": "text"
      },
      "source": [
        "From my experiments, I can conclude that Shallow Convnet performs better in CIFAR10 datset than Resnet and Resnet with Look ahead optimisers.\n",
        "\n",
        "Shallow ConvNet - 72.5%\n",
        "\n",
        "Resnet -65%\n",
        "\n",
        "Resnet with Lookahead Optimiser - 10%"
      ]
    }
  ]
}